{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch - CUDA available: True\n",
      "XGBoost is using the GPU.\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.6242674\ttotal: 6.2ms\tremaining: 55.8ms\n",
      "1:\tlearn: 0.5917165\ttotal: 6.79ms\tremaining: 27.2ms\n",
      "2:\tlearn: 0.5615844\ttotal: 7.22ms\tremaining: 16.9ms\n",
      "3:\tlearn: 0.5336707\ttotal: 8.19ms\tremaining: 12.3ms\n",
      "4:\tlearn: 0.4862918\ttotal: 8.57ms\tremaining: 8.57ms\n",
      "5:\tlearn: 0.4450405\ttotal: 8.93ms\tremaining: 5.96ms\n",
      "6:\tlearn: 0.4089812\ttotal: 9.42ms\tremaining: 4.04ms\n",
      "7:\tlearn: 0.3773298\ttotal: 9.78ms\tremaining: 2.45ms\n",
      "8:\tlearn: 0.3494304\ttotal: 10.1ms\tremaining: 1.13ms\n",
      "9:\tlearn: 0.3360929\ttotal: 10.6ms\tremaining: 0us\n",
      "CatBoost successfully used the GPU.\n",
      "FastAI is using the GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch - CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create a simple DMatrix\n",
    "dtrain = xgb.DMatrix(data=[[1, 2], [3, 4], [5, 6]], label=[0, 1, 0])\n",
    "\n",
    "# Train a small model with GPU support\n",
    "params = {\n",
    " 'tree_method': 'hist',  # Use the updated method\n",
    "        'device': 'cuda',       # Specify GPU usage\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(params, dtrain, num_boost_round=10)\n",
    "\n",
    "# If no errors occurred, XGBoost is using the GPU\n",
    "print(\"XGBoost is using the GPU.\")\n",
    "\n",
    "\n",
    "\n",
    "# CatBoost check\n",
    "from catboost import CatBoostClassifier\n",
    "# Initialize CatBoost model with GPU usage\n",
    "model = CatBoostClassifier(task_type='GPU', iterations=10)\n",
    "\n",
    "# Train on dummy data\n",
    "model.fit([[0, 1], [1, 0], [0, 0], [1, 1]], [0, 1, 0, 1])\n",
    "\n",
    "print(\"CatBoost successfully used the GPU.\")\n",
    "\n",
    "# FastAI check\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "# Create a simple DataFrame\n",
    "df = pd.DataFrame({'a': [1, 2, 3, 4, 5], 'b': [1, 0, 1, 0, 1], 'y': [0, 1, 0, 1, 0]})\n",
    "\n",
    "# Split the data\n",
    "dls = TabularDataLoaders.from_df(df, y_names='y', cat_names=['a'], cont_names=['b'], procs=[Categorify, Normalize])\n",
    "\n",
    "# Initialize a simple model\n",
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "\n",
    "# Check if FastAI is using GPU\n",
    "if torch.cuda.is_available():\n",
    "    learn.to_fp16()\n",
    "    print(\"FastAI is using the GPU.\")\n",
    "else:\n",
    "    print(\"FastAI is not using the GPU.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 2\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 3, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "LightGBM is using the GPU.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM check\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple dataset\n",
    "data = np.array([[1, 2], [3, 4], [5, 6]])  # Convert to NumPy array\n",
    "label = np.array([0, 1, 0])  # Convert to NumPy array\n",
    "train_data = lgb.Dataset(data, label=label)\n",
    "\n",
    "# Define parameters for LightGBM with GPU usage\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "gbm = lgb.train(params, train_data, num_boost_round=10)\n",
    "\n",
    "# If no errors occurred, LightGBM is using the GPU\n",
    "print(\"LightGBM is using the GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_1742/3390475948.py:18: DtypeWarning: Columns (63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(root_dir + 'final_data.csv')\n",
      "/tmp/ipykernel_1742/3390475948.py:19: DtypeWarning: Columns (63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_generated_df = pd.read_csv(root_dir + 'final_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_train_df after dropping ID:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Birthyear</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_personal_identifier</th>\n",
       "      <th>Customer_identification_number</th>\n",
       "      <th>Customer_registration_datetime</th>\n",
       "      <th>Customer_credit_rating</th>\n",
       "      <th>Customer_flag_change_of_authentication_1</th>\n",
       "      <th>Customer_flag_change_of_authentication_2</th>\n",
       "      <th>Customer_flag_change_of_authentication_3</th>\n",
       "      <th>Customer_flag_change_of_authentication_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_atm_transaction_datetime</th>\n",
       "      <th>Last_bank_branch_transaction_datetime</th>\n",
       "      <th>Flag_deposit_more_than_tenMillion</th>\n",
       "      <th>Unused_account_status</th>\n",
       "      <th>Recipient_account_suspend_status</th>\n",
       "      <th>Number_of_transaction_with_the_account</th>\n",
       "      <th>Transaction_history_with_the_account</th>\n",
       "      <th>First_time_iOS_by_vulnerable_user</th>\n",
       "      <th>Fraud_Type</th>\n",
       "      <th>Transaction_resumed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>female</td>\n",
       "      <td>조현준</td>\n",
       "      <td>uCPmTt-UEKUIYN</td>\n",
       "      <td>2008-01-30 03:49:41</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2009-01-20 23:10:39</td>\n",
       "      <td>2039-02-24 08:23:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2003-04-12 14:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995.0</td>\n",
       "      <td>female</td>\n",
       "      <td>안수진</td>\n",
       "      <td>QedXNL-ZYiNKYB</td>\n",
       "      <td>2008-11-16 14:28:15</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-09-27 04:31:25</td>\n",
       "      <td>2037-01-18 14:26:51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2024-09-16 15:58:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>female</td>\n",
       "      <td>류민준</td>\n",
       "      <td>qoGhFc-HUXuEjd</td>\n",
       "      <td>2010-05-11 06:53:06</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-05-05 14:37:19</td>\n",
       "      <td>2037-09-23 18:50:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2016-01-02 06:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964.0</td>\n",
       "      <td>female</td>\n",
       "      <td>우은주</td>\n",
       "      <td>TLIaDc-KXecOaP</td>\n",
       "      <td>2009-07-15 21:50:12</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-11-21 06:07:23</td>\n",
       "      <td>2043-04-01 17:34:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2003-11-28 06:14:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1968.0</td>\n",
       "      <td>male</td>\n",
       "      <td>이성진</td>\n",
       "      <td>DOcbBI-GDIdPah</td>\n",
       "      <td>2008-06-09 20:14:26</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-09-27 22:17:47</td>\n",
       "      <td>2018-07-12 12:39:16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>2003-04-12 14:53:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Birthyear Customer_Gender Customer_personal_identifier  \\\n",
       "0              1950.0          female                          조현준   \n",
       "1              1995.0          female                          안수진   \n",
       "2              2004.0          female                          류민준   \n",
       "3              1964.0          female                          우은주   \n",
       "4              1968.0            male                          이성진   \n",
       "\n",
       "  Customer_identification_number Customer_registration_datetime  \\\n",
       "0                 uCPmTt-UEKUIYN            2008-01-30 03:49:41   \n",
       "1                 QedXNL-ZYiNKYB            2008-11-16 14:28:15   \n",
       "2                 qoGhFc-HUXuEjd            2010-05-11 06:53:06   \n",
       "3                 TLIaDc-KXecOaP            2009-07-15 21:50:12   \n",
       "4                 DOcbBI-GDIdPah            2008-06-09 20:14:26   \n",
       "\n",
       "  Customer_credit_rating  Customer_flag_change_of_authentication_1  \\\n",
       "0                      A                                         0   \n",
       "1                      C                                         1   \n",
       "2                      B                                         1   \n",
       "3                      B                                         1   \n",
       "4                      E                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_2  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   Customer_flag_change_of_authentication_3  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_4  ...  \\\n",
       "0                                         0  ...   \n",
       "1                                         1  ...   \n",
       "2                                         1  ...   \n",
       "3                                         1  ...   \n",
       "4                                         1  ...   \n",
       "\n",
       "   Last_atm_transaction_datetime  Last_bank_branch_transaction_datetime  \\\n",
       "0            2009-01-20 23:10:39                    2039-02-24 08:23:20   \n",
       "1            2019-09-27 04:31:25                    2037-01-18 14:26:51   \n",
       "2            2011-05-05 14:37:19                    2037-09-23 18:50:20   \n",
       "3            2024-11-21 06:07:23                    2043-04-01 17:34:12   \n",
       "4            2025-09-27 22:17:47                    2018-07-12 12:39:16   \n",
       "\n",
       "   Flag_deposit_more_than_tenMillion Unused_account_status  \\\n",
       "0                                  1                     0   \n",
       "1                                  0                     0   \n",
       "2                                  1                     1   \n",
       "3                                  1                     1   \n",
       "4                                  0                     0   \n",
       "\n",
       "   Recipient_account_suspend_status  Number_of_transaction_with_the_account  \\\n",
       "0                                 0                                       0   \n",
       "1                                 1                                       1   \n",
       "2                                 1                                       1   \n",
       "3                                 0                                       0   \n",
       "4                                 0                                       1   \n",
       "\n",
       "   Transaction_history_with_the_account  First_time_iOS_by_vulnerable_user  \\\n",
       "0                                     4                                  0   \n",
       "1                                     2                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     1                                  0   \n",
       "\n",
       "   Fraud_Type  Transaction_resumed_date  \n",
       "0           a       2003-04-12 14:53:58  \n",
       "1           a       2024-09-16 15:58:27  \n",
       "2           a       2016-01-02 06:00:10  \n",
       "3           a       2003-11-28 06:14:09  \n",
       "4           a       2003-04-12 14:53:58  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df after dropping ID:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Customer_Birthyear</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_personal_identifier</th>\n",
       "      <th>Customer_identification_number</th>\n",
       "      <th>Customer_registration_datetime</th>\n",
       "      <th>Customer_credit_rating</th>\n",
       "      <th>Customer_flag_change_of_authentication_1</th>\n",
       "      <th>Customer_flag_change_of_authentication_2</th>\n",
       "      <th>Customer_flag_change_of_authentication_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Unused_terminal_status</th>\n",
       "      <th>Last_atm_transaction_datetime</th>\n",
       "      <th>Last_bank_branch_transaction_datetime</th>\n",
       "      <th>Flag_deposit_more_than_tenMillion</th>\n",
       "      <th>Unused_account_status</th>\n",
       "      <th>Recipient_account_suspend_status</th>\n",
       "      <th>Number_of_transaction_with_the_account</th>\n",
       "      <th>Transaction_history_with_the_account</th>\n",
       "      <th>First_time_iOS_by_vulnerable_user</th>\n",
       "      <th>Transaction_resumed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>1960</td>\n",
       "      <td>female</td>\n",
       "      <td>주지아</td>\n",
       "      <td>DOMcBN-kRMFflJ</td>\n",
       "      <td>2003-01-07 10:59:08</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-10 05:27:56</td>\n",
       "      <td>2003-01-08 05:27:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-08 05:27:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>1960</td>\n",
       "      <td>female</td>\n",
       "      <td>주지아</td>\n",
       "      <td>DOMcBN-kRMFflJ</td>\n",
       "      <td>2003-01-07 10:59:08</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-11 21:29:50</td>\n",
       "      <td>2003-01-08 05:27:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-08 05:27:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>1951</td>\n",
       "      <td>male</td>\n",
       "      <td>김정수</td>\n",
       "      <td>pZrAvI-mhxfVyw</td>\n",
       "      <td>2003-01-06 18:10:55</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-13 01:08:19</td>\n",
       "      <td>2003-01-13 01:08:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-13 01:08:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>1999</td>\n",
       "      <td>female</td>\n",
       "      <td>김현지</td>\n",
       "      <td>fVlbzX-wvugTpH</td>\n",
       "      <td>2003-01-08 05:28:53</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-21 10:03:32</td>\n",
       "      <td>2003-01-26 13:49:24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-20 10:03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>1996</td>\n",
       "      <td>female</td>\n",
       "      <td>박은정</td>\n",
       "      <td>chYftA-AjVuXMW</td>\n",
       "      <td>2003-01-17 03:37:22</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2003-01-28 19:04:19</td>\n",
       "      <td>2003-01-28 19:04:19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2003-01-28 19:04:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Customer_Birthyear Customer_Gender  \\\n",
       "0  TEST_000000                1960          female   \n",
       "1  TEST_000001                1960          female   \n",
       "2  TEST_000002                1951            male   \n",
       "3  TEST_000003                1999          female   \n",
       "4  TEST_000004                1996          female   \n",
       "\n",
       "  Customer_personal_identifier Customer_identification_number  \\\n",
       "0                          주지아                 DOMcBN-kRMFflJ   \n",
       "1                          주지아                 DOMcBN-kRMFflJ   \n",
       "2                          김정수                 pZrAvI-mhxfVyw   \n",
       "3                          김현지                 fVlbzX-wvugTpH   \n",
       "4                          박은정                 chYftA-AjVuXMW   \n",
       "\n",
       "  Customer_registration_datetime Customer_credit_rating  \\\n",
       "0            2003-01-07 10:59:08                      E   \n",
       "1            2003-01-07 10:59:08                      E   \n",
       "2            2003-01-06 18:10:55                      B   \n",
       "3            2003-01-08 05:28:53                      B   \n",
       "4            2003-01-17 03:37:22                      A   \n",
       "\n",
       "   Customer_flag_change_of_authentication_1  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   Customer_flag_change_of_authentication_2  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_3  ...  Unused_terminal_status  \\\n",
       "0                                         0  ...                       1   \n",
       "1                                         1  ...                       0   \n",
       "2                                         1  ...                       0   \n",
       "3                                         1  ...                       1   \n",
       "4                                         0  ...                       1   \n",
       "\n",
       "   Last_atm_transaction_datetime  Last_bank_branch_transaction_datetime  \\\n",
       "0            2003-01-10 05:27:56                    2003-01-08 05:27:56   \n",
       "1            2003-01-11 21:29:50                    2003-01-08 05:27:56   \n",
       "2            2003-01-13 01:08:19                    2003-01-13 01:08:19   \n",
       "3            2003-01-21 10:03:32                    2003-01-26 13:49:24   \n",
       "4            2003-01-28 19:04:19                    2003-01-28 19:04:19   \n",
       "\n",
       "   Flag_deposit_more_than_tenMillion Unused_account_status  \\\n",
       "0                                  0                     1   \n",
       "1                                  0                     1   \n",
       "2                                  1                     0   \n",
       "3                                  0                     1   \n",
       "4                                  0                     1   \n",
       "\n",
       "   Recipient_account_suspend_status  Number_of_transaction_with_the_account  \\\n",
       "0                                 1                                       0   \n",
       "1                                 0                                       0   \n",
       "2                                 0                                       2   \n",
       "3                                 1                                       0   \n",
       "4                                 1                                       0   \n",
       "\n",
       "   Transaction_history_with_the_account  First_time_iOS_by_vulnerable_user  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     2                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "\n",
       "   Transaction_resumed_date  \n",
       "0       2003-01-08 05:27:56  \n",
       "1       2003-01-08 05:27:56  \n",
       "2       2003-01-13 01:08:19  \n",
       "3       2003-01-20 10:03:32  \n",
       "4       2003-01-28 19:04:19  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_df (loaded from train.csv):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Birthyear</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_personal_identifier</th>\n",
       "      <th>Customer_identification_number</th>\n",
       "      <th>Customer_registration_datetime</th>\n",
       "      <th>Customer_credit_rating</th>\n",
       "      <th>Customer_flag_change_of_authentication_1</th>\n",
       "      <th>Customer_flag_change_of_authentication_2</th>\n",
       "      <th>Customer_flag_change_of_authentication_3</th>\n",
       "      <th>Customer_flag_change_of_authentication_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_atm_transaction_datetime</th>\n",
       "      <th>Last_bank_branch_transaction_datetime</th>\n",
       "      <th>Flag_deposit_more_than_tenMillion</th>\n",
       "      <th>Unused_account_status</th>\n",
       "      <th>Recipient_account_suspend_status</th>\n",
       "      <th>Number_of_transaction_with_the_account</th>\n",
       "      <th>Transaction_history_with_the_account</th>\n",
       "      <th>First_time_iOS_by_vulnerable_user</th>\n",
       "      <th>Fraud_Type</th>\n",
       "      <th>Transaction_resumed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>male</td>\n",
       "      <td>이상호</td>\n",
       "      <td>BJWQxd-WBASPLJ</td>\n",
       "      <td>2003-01-06 18:38:01</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-01-22 23:38:48</td>\n",
       "      <td>2003-01-22 23:38:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2003-01-22 23:38:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964</td>\n",
       "      <td>male</td>\n",
       "      <td>박상철</td>\n",
       "      <td>kurCwX-odPUXEt</td>\n",
       "      <td>2003-01-07 16:40:44</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-01-21 21:29:08</td>\n",
       "      <td>2003-01-31 00:19:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2003-01-19 21:29:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>female</td>\n",
       "      <td>조옥자</td>\n",
       "      <td>OiERQa-CTXBoaX</td>\n",
       "      <td>2003-01-11 14:08:36</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982</td>\n",
       "      <td>female</td>\n",
       "      <td>조옥자</td>\n",
       "      <td>OiERQa-CTXBoaX</td>\n",
       "      <td>2003-01-11 14:08:36</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-01-31 11:49:56</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982</td>\n",
       "      <td>female</td>\n",
       "      <td>조옥자</td>\n",
       "      <td>OiERQa-CTXBoaX</td>\n",
       "      <td>2003-01-11 14:08:36</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-01-31 11:49:56</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2003-01-31 07:13:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Birthyear Customer_Gender Customer_personal_identifier  \\\n",
       "0                1980            male                          이상호   \n",
       "1                1964            male                          박상철   \n",
       "2                1982          female                          조옥자   \n",
       "3                1982          female                          조옥자   \n",
       "4                1982          female                          조옥자   \n",
       "\n",
       "  Customer_identification_number Customer_registration_datetime  \\\n",
       "0                 BJWQxd-WBASPLJ            2003-01-06 18:38:01   \n",
       "1                 kurCwX-odPUXEt            2003-01-07 16:40:44   \n",
       "2                 OiERQa-CTXBoaX            2003-01-11 14:08:36   \n",
       "3                 OiERQa-CTXBoaX            2003-01-11 14:08:36   \n",
       "4                 OiERQa-CTXBoaX            2003-01-11 14:08:36   \n",
       "\n",
       "  Customer_credit_rating  Customer_flag_change_of_authentication_1  \\\n",
       "0                      B                                         0   \n",
       "1                      C                                         0   \n",
       "2                      B                                         1   \n",
       "3                      B                                         1   \n",
       "4                      B                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_2  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_3  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_4  ...  \\\n",
       "0                                         1  ...   \n",
       "1                                         0  ...   \n",
       "2                                         0  ...   \n",
       "3                                         0  ...   \n",
       "4                                         0  ...   \n",
       "\n",
       "   Last_atm_transaction_datetime  Last_bank_branch_transaction_datetime  \\\n",
       "0            2003-01-22 23:38:48                    2003-01-22 23:38:48   \n",
       "1            2003-01-21 21:29:08                    2003-01-31 00:19:46   \n",
       "2            2003-01-31 07:13:28                    2003-01-31 07:13:28   \n",
       "3            2003-01-31 11:49:56                    2003-01-31 07:13:28   \n",
       "4            2003-01-31 11:49:56                    2003-01-31 07:13:28   \n",
       "\n",
       "   Flag_deposit_more_than_tenMillion Unused_account_status  \\\n",
       "0                                  1                     1   \n",
       "1                                  0                     1   \n",
       "2                                  0                     0   \n",
       "3                                  1                     1   \n",
       "4                                  1                     0   \n",
       "\n",
       "   Recipient_account_suspend_status  Number_of_transaction_with_the_account  \\\n",
       "0                                 1                                       0   \n",
       "1                                 0                                       0   \n",
       "2                                 1                                       1   \n",
       "3                                 0                                       0   \n",
       "4                                 0                                       1   \n",
       "\n",
       "   Transaction_history_with_the_account  First_time_iOS_by_vulnerable_user  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     1                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     1                                  0   \n",
       "\n",
       "   Fraud_Type  Transaction_resumed_date  \n",
       "0           m       2003-01-22 23:38:48  \n",
       "1           m       2003-01-19 21:29:08  \n",
       "2           m       2003-01-31 07:13:28  \n",
       "3           m       2003-01-31 07:13:28  \n",
       "4           m       2003-01-31 07:13:28  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "\n",
    "## Evaluate the Model & save the preprocessor\n",
    "import joblib\n",
    "# Define the root directory\n",
    "root_dir = '/workspace/Dataset/FSI/'\n",
    "\n",
    "# Load the datasets\n",
    "# train_df = pd.read_csv(root_dir + 'train_sample.csv')\n",
    "# train_generated_df = pd.read_csv(root_dir + 'submission/filtered_data_3000.csv')\n",
    "# test_df = pd.read_csv(root_dir + 'test.csv')\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(root_dir + 'final_data.csv')\n",
    "train_generated_df = pd.read_csv(root_dir + 'final_data.csv')\n",
    "test_df = pd.read_csv(root_dir + 'test.csv')\n",
    "\n",
    "# Concatenate the training datasets\n",
    "# combined_train_df = pd.concat([train_df, train_generated_df], ignore_index=True)\n",
    "\n",
    "combined_train_df = train_generated_df\n",
    "\n",
    "# Drop the 'ID' column from training data (but not 'Fraud_Type')\n",
    "combined_train_df = combined_train_df.drop(columns=['ID'], errors='ignore')\n",
    "print(\"combined_train_df after dropping ID:\")\n",
    "display(combined_train_df.head())  # Displays the first few rows after dropping 'ID'\n",
    "\n",
    "test_df = test_df.drop(columns=['Fraud_Type'],errors='ignore')\n",
    "print(\"test_df after dropping ID:\")\n",
    "display(test_df.head())  # Displays the first few rows after dropping 'ID'\n",
    "\n",
    "# Check if val.csv exists; if not, split the combined_train_df\n",
    "val_file_path = root_dir + 'train.csv'\n",
    "if os.path.exists(val_file_path):\n",
    "    val_df = pd.read_csv(val_file_path)\n",
    "    val_df = val_df.drop(columns=['ID'], errors='ignore')  # Only drop 'ID', keep 'Fraud_Type' as the label\n",
    "    print(\"val_df (loaded from train.csv):\")\n",
    "    display(val_df.head())  # Displays the first few rows of val_df\n",
    "else:\n",
    "    combined_train_df, val_df = train_test_split(combined_train_df, test_size=0.2, random_state=42)\n",
    "    print(\"combined_train_df after splitting:\")\n",
    "    display(combined_train_df.head())  # Displays the first few rows of combined_train_df after splitting\n",
    "    print(\"val_df (created by splitting):\")\n",
    "    display(val_df.head())  # Displays the first few rows of val_df created by splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "We now specify the `Fraud_Type` as the target column and use AutoGluon's `TabularPredictor` to train the model with the `best_quality` preset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240827_130156\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #129~20.04.1-Ubuntu SMP Wed Aug 7 13:07:13 UTC 2024\n",
      "CPU Count:          20\n",
      "Memory Avail:       24.61 GB / 31.15 GB (79.0%)\n",
      "Disk Space Avail:   191.92 GB / 467.89 GB (41.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (130000 samples, 263.72 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240827_130156\"\n",
      "Train Data Rows:    130000\n",
      "Train Data Columns: 62\n",
      "Tuning Data Rows:    120000\n",
      "Tuning Data Columns: 62\n",
      "Label Column:       Fraud_Type\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 13) unique label values:  ['a', 'j', 'h', 'k', 'c', 'g', 'i', 'b', 'f', 'd']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 13\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25465.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 469.40 MB (1.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 27 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Location', 'Time_difference']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 10000 to 3090 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Another_Person_Account']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  5 | ['Customer_Birthyear', 'Account_initial_balance', 'Account_balance', 'Transaction_Amount', 'Distance']\n",
      "\t\t('int', [])                        : 33 | ['Customer_flag_change_of_authentication_1', 'Customer_flag_change_of_authentication_2', 'Customer_flag_change_of_authentication_3', 'Customer_flag_change_of_authentication_4', 'Customer_rooting_jailbreak_indicator', ...]\n",
      "\t\t('object', [])                     : 15 | ['Customer_Gender', 'Customer_personal_identifier', 'Customer_identification_number', 'Customer_credit_rating', 'Customer_loan_type', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  6 | ['Customer_registration_datetime', 'Account_creation_datetime', 'Transaction_Datetime', 'Last_atm_transaction_datetime', 'Last_bank_branch_transaction_datetime', ...]\n",
      "\t\t('object', ['text'])               :  2 | ['Location', 'Time_difference']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   12 | ['Customer_personal_identifier', 'Customer_identification_number', 'Customer_credit_rating', 'Customer_loan_type', 'Account_account_number', ...]\n",
      "\t\t('category', ['text_as_category'])  :    2 | ['Location', 'Time_difference']\n",
      "\t\t('float', [])                       :    5 | ['Customer_Birthyear', 'Account_initial_balance', 'Account_balance', 'Transaction_Amount', 'Distance']\n",
      "\t\t('int', [])                         :    9 | ['Account_amount_daily_limit', 'Account_remaining_amount_daily_limit_exceeded', 'Account_one_month_max_amount', 'Account_one_month_std_dev', 'Account_dawn_one_month_max_amount', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :   13 | ['Location.char_count', 'Location.word_count', 'Location.lower_ratio', 'Location.digit_ratio', 'Location.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   27 | ['Customer_Gender', 'Customer_flag_change_of_authentication_1', 'Customer_flag_change_of_authentication_2', 'Customer_flag_change_of_authentication_3', 'Customer_flag_change_of_authentication_4', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :   30 | ['Customer_registration_datetime', 'Customer_registration_datetime.year', 'Customer_registration_datetime.month', 'Customer_registration_datetime.day', 'Customer_registration_datetime.dayofweek', ...]\n",
      "\t\t('int', ['text_ngram'])             : 1040 | ['__nlp__.00', '__nlp__.00 01', '__nlp__.00 01 10', '__nlp__.00 01 16', '__nlp__.00 01 58', ...]\n",
      "\t46.1s = Fit runtime\n",
      "\t61 features in original data used to generate 1138 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 594.62 MB (2.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 47.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.9894\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t156.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.9895\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t156.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.3601\t = Validation score   (accuracy)\n",
      "\t881.35s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9934\t = Validation score   (accuracy)\n",
      "\t14.0s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9922\t = Validation score   (accuracy)\n",
      "\t15.5s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4668\t = Validation score   (accuracy)\n",
      "\t13.31s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6733\t = Validation score   (accuracy)\n",
      "\t13.51s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (1138), dynamically setting 'colsample_bylevel' to 0.8787346221441125 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.9166\t = Validation score   (accuracy)\n",
      "\t353.72s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.812\t = Validation score   (accuracy)\n",
      "\t14.43s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8316\t = Validation score   (accuracy)\n",
      "\t14.53s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.3359\t = Validation score   (accuracy)\n",
      "\t113.32s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.3679\t = Validation score   (accuracy)\n",
      "\t79.48s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9908\t = Validation score   (accuracy)\n",
      "\t11.9s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.5, 'LightGBMXT': 0.182, 'LightGBMLarge': 0.136, 'KNeighborsUnif': 0.091, 'ExtraTreesEntr': 0.091}\n",
      "\t0.997\t = Validation score   (accuracy)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1906.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 753.5 rows/s (120000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240827_130156\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2   0.997025    accuracy     159.250082  398.818386                0.008063           3.748007            2       True         14\n",
      "1            LightGBMXT   0.993425    accuracy       0.948882   13.996720                0.948882          13.996720            1       True          4\n",
      "2              LightGBM   0.992167    accuracy       0.874973   15.500237                0.874973          15.500237            1       True          5\n",
      "3         LightGBMLarge   0.990775    accuracy       0.639179   11.904474                0.639179          11.904474            1       True         13\n",
      "4        KNeighborsDist   0.989483    accuracy     156.479294    0.916233              156.479294           0.916233            1       True          2\n",
      "5        KNeighborsUnif   0.989367    accuracy     156.067117    0.916059              156.067117           0.916059            1       True          1\n",
      "6              CatBoost   0.916575    accuracy       0.257887  353.721380                0.257887         353.721380            1       True          8\n",
      "7        ExtraTreesEntr   0.831592    accuracy       1.328954   14.531747                1.328954          14.531747            1       True         10\n",
      "8        ExtraTreesGini   0.812008    accuracy       1.750186   14.426270                1.750186          14.426270            1       True          9\n",
      "9      RandomForestEntr   0.673283    accuracy       1.222466   13.513191                1.222466          13.513191            1       True          7\n",
      "10     RandomForestGini   0.466817    accuracy       1.233672   13.314689                1.233672          13.314689            1       True          6\n",
      "11       NeuralNetTorch   0.367908    accuracy       0.721249   79.478487                0.721249          79.478487            1       True         12\n",
      "12      NeuralNetFastAI   0.360075    accuracy       1.112005  881.347559                1.112005         881.347559            1       True          3\n",
      "13              XGBoost   0.335917    accuracy       1.510124  113.317425                1.510124         113.317425            1       True         11\n"
     ]
    }
   ],
   "source": [
    "# Specify the target column for classification\n",
    "label = 'Fraud_Type'\n",
    "\n",
    "\n",
    "# Initialize the TabularPredictor\n",
    "predictor = TabularPredictor(label=label, eval_metric='accuracy' ).fit(\n",
    "    train_data=TabularDataset(combined_train_df), \n",
    "    tuning_data=TabularDataset(val_df), \n",
    "    # presets='best_quality',# Options: 'best_quality', 'high_quality', 'good_quality', 'medium_quality'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "leaderboard = predictor.leaderboard(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model \n",
    "\n",
    "Let's evaluate the model on both the training and validation datasets to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance metrics:\n",
      "{'accuracy': 1.0, 'balanced_accuracy': 1.0, 'mcc': 1.0}\n",
      "\n",
      "Validation performance metrics:\n",
      "{'accuracy': 0.997025, 'balanced_accuracy': 0.8060858585858586, 'mcc': 0.8426993150522791}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on the training and validation datasets\n",
    "train_performance = predictor.evaluate(combined_train_df)\n",
    "val_performance = predictor.evaluate(val_df)\n",
    "\n",
    "# Display performance metrics\n",
    "print(\"Training performance metrics:\")\n",
    "print(train_performance)\n",
    "\n",
    "print(\"\\nValidation performance metrics:\")\n",
    "print(val_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the preprocessor used in Autogluon for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/Dataset/FSI/preprocessor.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the feature generator from the predictor\n",
    "preprocessor = predictor._learner.feature_generator\n",
    "\n",
    "# Save the preprocessor using joblib\n",
    "import joblib\n",
    "joblib.dump(preprocessor, root_dir + 'preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Classification Report\n",
    "\n",
    "We'll generate a detailed classification report for each fraud type using the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Type: a\n",
      "  precision: 0.96\n",
      "  recall: 0.48\n",
      "  f1-score: 0.64\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: b\n",
      "  precision: 0.7966101694915254\n",
      "  recall: 0.94\n",
      "  f1-score: 0.8623853211009174\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: c\n",
      "  precision: 0.925531914893617\n",
      "  recall: 0.87\n",
      "  f1-score: 0.8969072164948454\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: d\n",
      "  precision: 0.9125\n",
      "  recall: 0.73\n",
      "  f1-score: 0.811111111111111\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: e\n",
      "  precision: 0.9245283018867925\n",
      "  recall: 0.98\n",
      "  f1-score: 0.9514563106796116\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: f\n",
      "  precision: 0.9705882352941176\n",
      "  recall: 0.99\n",
      "  f1-score: 0.9801980198019802\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: g\n",
      "  precision: 0.8362068965517241\n",
      "  recall: 0.97\n",
      "  f1-score: 0.8981481481481481\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: h\n",
      "  precision: 0.9620253164556962\n",
      "  recall: 0.76\n",
      "  f1-score: 0.8491620111731845\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: i\n",
      "  precision: 0.6\n",
      "  recall: 0.12\n",
      "  f1-score: 0.19999999999999998\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: j\n",
      "  precision: 0.9479166666666666\n",
      "  recall: 0.91\n",
      "  f1-score: 0.9285714285714285\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: k\n",
      "  precision: 0.9263157894736842\n",
      "  recall: 0.88\n",
      "  f1-score: 0.9025641025641025\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: l\n",
      "  precision: 0.85\n",
      "  recall: 0.85\n",
      "  f1-score: 0.85\n",
      "  support: 100.0\n",
      "\n",
      "Fraud Type: m\n",
      "  precision: 0.9979065778853915\n",
      "  recall: 0.9991161616161616\n",
      "  f1-score: 0.9985110034322632\n",
      "  support: 118800.0\n",
      "\n",
      "Fraud Type: macro avg\n",
      "  precision: 0.8930869129691702\n",
      "  recall: 0.8060858585858586\n",
      "  f1-score: 0.8283857440828917\n",
      "  support: 120000.0\n",
      "\n",
      "Fraud Type: weighted avg\n",
      "  precision: 0.9967710315154658\n",
      "  recall: 0.997025\n",
      "  f1-score: 0.9966679797893117\n",
      "  support: 120000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set and calculate per-class scores\n",
    "val_predictions = predictor.predict(val_df)\n",
    "val_true = val_df[label]\n",
    "classification_report_per_class = classification_report(val_true, val_predictions, output_dict=True)\n",
    "\n",
    "# Display classification report for each fraud type\n",
    "for fraud_type, metrics in classification_report_per_class.items():\n",
    "    if isinstance(metrics, dict):  # Filter out 'accuracy' and other aggregate scores\n",
    "        print(f\"Fraud Type: {fraud_type}\")\n",
    "        for metric, score in metrics.items():\n",
    "            print(f\"  {metric}: {score}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on the Test Set\n",
    "\n",
    "We now make predictions on the test set and prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to /workspace/Dataset/FSI/clf_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = predictor.predict(test_df)\n",
    "\n",
    "\n",
    "# Prepare the submission file using the ID column from the test data\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],  # Replace 'ID' with the actual ID column name in your test.csv\n",
    "    'Fraud_Type': predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_file_path = root_dir + 'clf_submission.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {submission_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syn_Submission Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1742/1190912584.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = correct_predictions_df.groupby('Fraud_Type').apply(lambda x: x.nlargest(1000, 'Confidence_Score')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "train_generated_df['Predicted_Fraud_Type'] = predictor.predict(train_generated_df)\n",
    "probabilities = predictor.predict_proba(train_generated_df)\n",
    "train_generated_df['Confidence_Score'] = probabilities.max(axis=1)\n",
    "\n",
    "correct_predictions_df = train_generated_df[train_generated_df['Fraud_Type'] == train_generated_df['Predicted_Fraud_Type']]\n",
    "\n",
    "# Step 3: Sort by confidence score and select the top 1000 samples per Fraud_Type\n",
    "sampled_df = correct_predictions_df.groupby('Fraud_Type').apply(lambda x: x.nlargest(1000, 'Confidence_Score')).reset_index(drop=True)\n",
    "\n",
    "# Step 4: (Optional) Remove the 'Predicted_Fraud_Type' and 'Confidence_Score' columns if not needed\n",
    "sampled_df = sampled_df.drop(columns=['Predicted_Fraud_Type', 'Confidence_Score'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(root_dir + 'generated_data_submission.csv')\n",
    "submission_dtypes = test_df.dtypes\n",
    "sampled_df  = sampled_df[submission_format.columns]\n",
    "\n",
    "# Convert the syn_submission.csv columns to match the train.csv data types\n",
    "for column in submission_format.columns:\n",
    "    if column =='ID' or column==\"Fraud_Type\":\n",
    "        continue\n",
    "    if sampled_df[column].dtype != submission_dtypes [column]:\n",
    "        sampled_df[column] = sampled_df[column].astype(submission_dtypes [column])\n",
    "        print(f\"column '{column}' different!\")\n",
    "\n",
    "\n",
    "# Save the sampled DataFrame\n",
    "sampled_df.to_csv(root_dir + 'syn_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
