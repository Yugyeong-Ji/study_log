{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalous Financial Transaction Detection\n",
    "\n",
    "본 대회의 과제는 금융 거래 데이터에서 **이상 거래를 탐지하는 기능**을 개선하고 활용도를 높이는 분류 AI모델을 개발하는 것입니다. \n",
    "\n",
    "특히, 클래스 불균형 문제를 해결하기 위해 오픈소스 생성형 AI 모델을 활용하여 부족한 클래스의 데이터를 보완하고, 이를 통해 분류 모델의 성능을 향상시키는 것이 핵심 목표입니다. \n",
    "\n",
    "이러한 접근을 통해 금융보안에 특화된 데이터 분석 및 활용 역량을 강화하여 전문 인력을 양성하고, 금융권의 AI 활용 어려움에 따른 해결 방안을 함께 모색하며 금융 산업의 AI 활용 활성화를 지원하는 것을 목표로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성 관련\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# 데이터 처리 및 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 머신러닝 전처리\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# 머신러닝 모델\n",
    "import xgboost as xgb\n",
    "\n",
    "# 합성 데이터 생성\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# To ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pycaret AutoML 사용\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "from pycaret.classification import ClassificationExperiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 생성 🏭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_csv(\"/workspace/Dataset/FSI/clip_downloads/FSI/train_features.csv\")\n",
    "test_all = pd.read_csv(\"/workspace/Dataset/FSI/clip_downloads/FSI/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synthetic_data = pd.read_csv(\"/workspace/Dataset/FSI/clip_downloads/FSI/generated_data_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본 데이터와 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 257)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_train = train_all.drop(columns=\"ID\")\n",
    "all_synthetic_data = all_synthetic_data.drop(columns=\"ID\")\n",
    "train_total = pd.concat([origin_train, all_synthetic_data], ignore_index=True)\n",
    "train_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_247</th>\n",
       "      <th>Feature_248</th>\n",
       "      <th>Feature_249</th>\n",
       "      <th>Feature_250</th>\n",
       "      <th>Feature_251</th>\n",
       "      <th>Feature_252</th>\n",
       "      <th>Feature_253</th>\n",
       "      <th>Feature_254</th>\n",
       "      <th>Feature_255</th>\n",
       "      <th>Fraud_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880163</td>\n",
       "      <td>-1.119654</td>\n",
       "      <td>-1.288096</td>\n",
       "      <td>-1.374387</td>\n",
       "      <td>0.616114</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>-0.598587</td>\n",
       "      <td>0.601537</td>\n",
       "      <td>1.324492</td>\n",
       "      <td>1.096167</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.058133</td>\n",
       "      <td>1.355208</td>\n",
       "      <td>-1.785255</td>\n",
       "      <td>1.475678</td>\n",
       "      <td>-0.136004</td>\n",
       "      <td>-1.324057</td>\n",
       "      <td>-0.334166</td>\n",
       "      <td>0.770605</td>\n",
       "      <td>0.711004</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.900374</td>\n",
       "      <td>-1.119269</td>\n",
       "      <td>-1.350800</td>\n",
       "      <td>-1.363732</td>\n",
       "      <td>0.645792</td>\n",
       "      <td>0.504497</td>\n",
       "      <td>-0.533358</td>\n",
       "      <td>0.610816</td>\n",
       "      <td>1.312548</td>\n",
       "      <td>1.082016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.993603</td>\n",
       "      <td>1.396403</td>\n",
       "      <td>-1.887138</td>\n",
       "      <td>1.484958</td>\n",
       "      <td>-0.120737</td>\n",
       "      <td>-1.272975</td>\n",
       "      <td>-0.418074</td>\n",
       "      <td>0.751052</td>\n",
       "      <td>0.684775</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869114</td>\n",
       "      <td>-1.126157</td>\n",
       "      <td>-1.294111</td>\n",
       "      <td>-1.388630</td>\n",
       "      <td>0.629380</td>\n",
       "      <td>0.501532</td>\n",
       "      <td>-0.557485</td>\n",
       "      <td>0.596676</td>\n",
       "      <td>1.332982</td>\n",
       "      <td>1.103749</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.016553</td>\n",
       "      <td>1.357152</td>\n",
       "      <td>-1.832411</td>\n",
       "      <td>1.478184</td>\n",
       "      <td>-0.158911</td>\n",
       "      <td>-1.305501</td>\n",
       "      <td>-0.409247</td>\n",
       "      <td>0.765062</td>\n",
       "      <td>0.687483</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878418</td>\n",
       "      <td>-1.125741</td>\n",
       "      <td>-1.310068</td>\n",
       "      <td>-1.376499</td>\n",
       "      <td>0.635101</td>\n",
       "      <td>0.496822</td>\n",
       "      <td>-0.559677</td>\n",
       "      <td>0.611012</td>\n",
       "      <td>1.325877</td>\n",
       "      <td>1.097270</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.016051</td>\n",
       "      <td>1.372284</td>\n",
       "      <td>-1.853848</td>\n",
       "      <td>1.480517</td>\n",
       "      <td>-0.148698</td>\n",
       "      <td>-1.292589</td>\n",
       "      <td>-0.425839</td>\n",
       "      <td>0.758834</td>\n",
       "      <td>0.695257</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.217422</td>\n",
       "      <td>-1.414048</td>\n",
       "      <td>-0.178742</td>\n",
       "      <td>-0.854678</td>\n",
       "      <td>0.289796</td>\n",
       "      <td>0.225006</td>\n",
       "      <td>-0.762616</td>\n",
       "      <td>-0.670094</td>\n",
       "      <td>0.705489</td>\n",
       "      <td>1.033402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072828</td>\n",
       "      <td>1.090991</td>\n",
       "      <td>-1.761935</td>\n",
       "      <td>0.367776</td>\n",
       "      <td>-0.313025</td>\n",
       "      <td>-0.949463</td>\n",
       "      <td>-1.672828</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0.799470</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0   0.880163  -1.119654  -1.288096  -1.374387   0.616114   0.527632   \n",
       "1   0.900374  -1.119269  -1.350800  -1.363732   0.645792   0.504497   \n",
       "2   0.869114  -1.126157  -1.294111  -1.388630   0.629380   0.501532   \n",
       "3   0.878418  -1.125741  -1.310068  -1.376499   0.635101   0.496822   \n",
       "4   1.217422  -1.414048  -0.178742  -0.854678   0.289796   0.225006   \n",
       "\n",
       "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_247  Feature_248  \\\n",
       "0  -0.598587   0.601537   1.324492   1.096167  ...    -1.058133     1.355208   \n",
       "1  -0.533358   0.610816   1.312548   1.082016  ...    -0.993603     1.396403   \n",
       "2  -0.557485   0.596676   1.332982   1.103749  ...    -1.016553     1.357152   \n",
       "3  -0.559677   0.611012   1.325877   1.097270  ...    -1.016051     1.372284   \n",
       "4  -0.762616  -0.670094   0.705489   1.033402  ...    -0.072828     1.090991   \n",
       "\n",
       "   Feature_249  Feature_250  Feature_251  Feature_252  Feature_253  \\\n",
       "0    -1.785255     1.475678    -0.136004    -1.324057    -0.334166   \n",
       "1    -1.887138     1.484958    -0.120737    -1.272975    -0.418074   \n",
       "2    -1.832411     1.478184    -0.158911    -1.305501    -0.409247   \n",
       "3    -1.853848     1.480517    -0.148698    -1.292589    -0.425839   \n",
       "4    -1.761935     0.367776    -0.313025    -0.949463    -1.672828   \n",
       "\n",
       "   Feature_254  Feature_255  Fraud_Type  \n",
       "0     0.770605     0.711004        12.0  \n",
       "1     0.751052     0.684775        12.0  \n",
       "2     0.765062     0.687483        12.0  \n",
       "3     0.758834     0.695257        12.0  \n",
       "4     0.685014     0.799470        12.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 생성 및 작업 디렉토리 변경\n",
    "os.makedirs('/workspace/Dataset/FSI/clip_downloads/submission', exist_ok=True)\n",
    "os.chdir(\"/workspace/Dataset/FSI/clip_downloads/submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing : pycaret setup / pycaret exp(init class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycaret.classification.oop.ClassificationExperiment"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = ClassificationExperiment()\n",
    "type(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_263d3_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_263d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_263d3_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_263d3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_263d3_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_263d3_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_263d3_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_263d3_row1_col1\" class=\"data row1 col1\" >Fraud_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_263d3_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_263d3_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_263d3_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_263d3_row3_col1\" class=\"data row3 col1\" >(250000, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_263d3_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_263d3_row4_col1\" class=\"data row4 col1\" >(250000, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_263d3_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_263d3_row5_col1\" class=\"data row5 col1\" >(175000, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_263d3_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_263d3_row6_col1\" class=\"data row6 col1\" >(75000, 257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_263d3_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_263d3_row7_col1\" class=\"data row7 col1\" >256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_263d3_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_263d3_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_263d3_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_263d3_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_263d3_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_263d3_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_263d3_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_263d3_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_263d3_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_263d3_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_263d3_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_263d3_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_263d3_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_263d3_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_263d3_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_263d3_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_263d3_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_263d3_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_263d3_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_263d3_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_263d3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_263d3_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_263d3_row18_col1\" class=\"data row18 col1\" >f46b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f28b4f72590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7f27b5e0bfd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(train_total, target = 'Fraud_Type', session_id = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models : 모델 선정(autoML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf',\n",
      "       'qda', 'ada', 'gbc', 'lda', 'et', 'xgboost', 'lightgbm', 'dummy'],\n",
      "      dtype='object', name='ID')\n"
     ]
    }
   ],
   "source": [
    "print(exp.models().index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2cb9b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2cb9b_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2cb9b_row0_col1, #T_2cb9b_row0_col2, #T_2cb9b_row0_col3, #T_2cb9b_row0_col4, #T_2cb9b_row0_col5, #T_2cb9b_row0_col6, #T_2cb9b_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2cb9b_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2cb9b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2cb9b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2cb9b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2cb9b_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_2cb9b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2cb9b_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_2cb9b_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_2cb9b_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_2cb9b_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_2cb9b_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2cb9b_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_2cb9b_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_2cb9b_row0_col1\" class=\"data row0 col1\" >0.5895</td>\n",
       "      <td id=\"T_2cb9b_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_2cb9b_row0_col3\" class=\"data row0 col3\" >0.5895</td>\n",
       "      <td id=\"T_2cb9b_row0_col4\" class=\"data row0 col4\" >0.5530</td>\n",
       "      <td id=\"T_2cb9b_row0_col5\" class=\"data row0 col5\" >0.5543</td>\n",
       "      <td id=\"T_2cb9b_row0_col6\" class=\"data row0 col6\" >0.3569</td>\n",
       "      <td id=\"T_2cb9b_row0_col7\" class=\"data row0 col7\" >0.3695</td>\n",
       "      <td id=\"T_2cb9b_row0_col8\" class=\"data row0 col8\" >15.3900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f28b194e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4086 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c4086_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c4086_row0_col1, #T_c4086_row0_col2, #T_c4086_row0_col3, #T_c4086_row0_col4, #T_c4086_row0_col5, #T_c4086_row0_col6, #T_c4086_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_c4086_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4086\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4086_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c4086_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_c4086_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_c4086_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_c4086_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_c4086_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_c4086_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_c4086_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_c4086_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4086_level0_row0\" class=\"row_heading level0 row0\" >knn</th>\n",
       "      <td id=\"T_c4086_row0_col0\" class=\"data row0 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_c4086_row0_col1\" class=\"data row0 col1\" >0.5361</td>\n",
       "      <td id=\"T_c4086_row0_col2\" class=\"data row0 col2\" >0.7172</td>\n",
       "      <td id=\"T_c4086_row0_col3\" class=\"data row0 col3\" >0.5361</td>\n",
       "      <td id=\"T_c4086_row0_col4\" class=\"data row0 col4\" >0.5201</td>\n",
       "      <td id=\"T_c4086_row0_col5\" class=\"data row0 col5\" >0.5248</td>\n",
       "      <td id=\"T_c4086_row0_col6\" class=\"data row0 col6\" >0.3233</td>\n",
       "      <td id=\"T_c4086_row0_col7\" class=\"data row0 col7\" >0.3248</td>\n",
       "      <td id=\"T_c4086_row0_col8\" class=\"data row0 col8\" >6.8540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f27a8c29120>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17602 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_17602_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_17602_row0_col1, #T_17602_row0_col2, #T_17602_row0_col3, #T_17602_row0_col4, #T_17602_row0_col5, #T_17602_row0_col6, #T_17602_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_17602_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17602\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17602_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_17602_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_17602_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_17602_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_17602_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_17602_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_17602_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_17602_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_17602_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17602_level0_row0\" class=\"row_heading level0 row0\" >nb</th>\n",
       "      <td id=\"T_17602_row0_col0\" class=\"data row0 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_17602_row0_col1\" class=\"data row0 col1\" >0.3258</td>\n",
       "      <td id=\"T_17602_row0_col2\" class=\"data row0 col2\" >0.6426</td>\n",
       "      <td id=\"T_17602_row0_col3\" class=\"data row0 col3\" >0.3258</td>\n",
       "      <td id=\"T_17602_row0_col4\" class=\"data row0 col4\" >0.5019</td>\n",
       "      <td id=\"T_17602_row0_col5\" class=\"data row0 col5\" >0.3058</td>\n",
       "      <td id=\"T_17602_row0_col6\" class=\"data row0 col6\" >0.2654</td>\n",
       "      <td id=\"T_17602_row0_col7\" class=\"data row0 col7\" >0.3155</td>\n",
       "      <td id=\"T_17602_row0_col8\" class=\"data row0 col8\" >0.5090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f27b5e09750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5895 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5895_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5895_row0_col1, #T_f5895_row0_col2, #T_f5895_row0_col3, #T_f5895_row0_col4, #T_f5895_row0_col5, #T_f5895_row0_col6, #T_f5895_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f5895_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5895\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5895_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f5895_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f5895_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_f5895_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_f5895_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_f5895_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_f5895_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_f5895_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_f5895_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5895_level0_row0\" class=\"row_heading level0 row0\" >dt</th>\n",
       "      <td id=\"T_f5895_row0_col0\" class=\"data row0 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_f5895_row0_col1\" class=\"data row0 col1\" >0.4455</td>\n",
       "      <td id=\"T_f5895_row0_col2\" class=\"data row0 col2\" >0.6049</td>\n",
       "      <td id=\"T_f5895_row0_col3\" class=\"data row0 col3\" >0.4455</td>\n",
       "      <td id=\"T_f5895_row0_col4\" class=\"data row0 col4\" >0.4508</td>\n",
       "      <td id=\"T_f5895_row0_col5\" class=\"data row0 col5\" >0.4480</td>\n",
       "      <td id=\"T_f5895_row0_col6\" class=\"data row0 col6\" >0.2328</td>\n",
       "      <td id=\"T_f5895_row0_col7\" class=\"data row0 col7\" >0.2329</td>\n",
       "      <td id=\"T_f5895_row0_col8\" class=\"data row0 col8\" >8.8720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f27a8c70ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76f28 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_76f28_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_76f28_row0_col1, #T_76f28_row0_col2, #T_76f28_row0_col3, #T_76f28_row0_col4, #T_76f28_row0_col5, #T_76f28_row0_col6, #T_76f28_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_76f28_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76f28\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_76f28_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_76f28_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_76f28_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_76f28_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_76f28_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_76f28_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_76f28_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_76f28_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_76f28_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76f28_level0_row0\" class=\"row_heading level0 row0\" >svm</th>\n",
       "      <td id=\"T_76f28_row0_col0\" class=\"data row0 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_76f28_row0_col1\" class=\"data row0 col1\" >0.5729</td>\n",
       "      <td id=\"T_76f28_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_76f28_row0_col3\" class=\"data row0 col3\" >0.5729</td>\n",
       "      <td id=\"T_76f28_row0_col4\" class=\"data row0 col4\" >0.5083</td>\n",
       "      <td id=\"T_76f28_row0_col5\" class=\"data row0 col5\" >0.5169</td>\n",
       "      <td id=\"T_76f28_row0_col6\" class=\"data row0 col6\" >0.3089</td>\n",
       "      <td id=\"T_76f28_row0_col7\" class=\"data row0 col7\" >0.3296</td>\n",
       "      <td id=\"T_76f28_row0_col8\" class=\"data row0 col8\" >2.8400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f27a8c37760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>12:50:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   \n",
       "                                                                   \n",
       "Initiated  . . . . . . . . . . . . . . . . . .             12:50:41\n",
       "Status     . . . . . . . . . . . . . . . . . .     Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  SVM - Radial Kernel"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Accuracy, AUC, Recall, Prec., F1, Kappa, MCC, TT (Sec)]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c684fc9b08404e6ca1fad409e3a6cb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exp\u001b[38;5;241m.\u001b[39mmodels()\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pycaret/classification/oop.py:1180\u001b[0m, in \u001b[0;36mClassificationExperiment.compare_models\u001b[0;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, engine, verbose, parallel)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_engine(estimator\u001b[38;5;241m=\u001b[39mestimator, engine\u001b[38;5;241m=\u001b[39meng, severity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturbo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaller_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1201\u001b[0m         \u001b[38;5;66;03m# Reset the models back to the default engines\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:794\u001b[0m, in \u001b[0;36m_SupervisedExperiment.compare_models\u001b[0;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, verbose, parallel, caller_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m results_columns_to_ignore \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 794\u001b[0m     model, model_fit_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_model_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpull(pop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    797\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    798\u001b[0m             model_results\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    803\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:1533\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[0;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit_time\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m-> 1533\u001b[0m model, model_fit_time, model_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model_with_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;66;03m# end runtime\u001b[39;00m\n\u001b[1;32m   1550\u001b[0m runtime_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:1126\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[0;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, error_score, return_train_score)\u001b[0m\n\u001b[1;32m   1124\u001b[0m     model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[0;32m-> 1126\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpipeline_with_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1140\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for id in exp.models().index[5:]:\n",
    "    if(id is 'rbfsvm'):\n",
    "        continue\n",
    "    exp.compare_models(include = [id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ce175 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ce175_row0_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ce175_row0_col1, #T_ce175_row0_col2, #T_ce175_row0_col3, #T_ce175_row0_col4, #T_ce175_row0_col5, #T_ce175_row0_col6, #T_ce175_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_ce175_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ce175\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce175_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ce175_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_ce175_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_ce175_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_ce175_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_ce175_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_ce175_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_ce175_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_ce175_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce175_level0_row0\" class=\"row_heading level0 row0\" >xgboost</th>\n",
       "      <td id=\"T_ce175_row0_col0\" class=\"data row0 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_ce175_row0_col1\" class=\"data row0 col1\" >0.5909</td>\n",
       "      <td id=\"T_ce175_row0_col2\" class=\"data row0 col2\" >0.7995</td>\n",
       "      <td id=\"T_ce175_row0_col3\" class=\"data row0 col3\" >0.5909</td>\n",
       "      <td id=\"T_ce175_row0_col4\" class=\"data row0 col4\" >0.5765</td>\n",
       "      <td id=\"T_ce175_row0_col5\" class=\"data row0 col5\" >0.5560</td>\n",
       "      <td id=\"T_ce175_row0_col6\" class=\"data row0 col6\" >0.3508</td>\n",
       "      <td id=\"T_ce175_row0_col7\" class=\"data row0 col7\" >0.3664</td>\n",
       "      <td id=\"T_ce175_row0_col8\" class=\"data row0 col8\" >21.8410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f28c59d8940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = exp.compare_models(include = ['xgboost']) #compare models by OOP method(nothing different from compare_models() function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['Feature_0', 'Feature_1',\n",
       "                                              'Feature_2', 'Feature_3',\n",
       "                                              'Feature_4', 'Feature_5',\n",
       "                                              'Feature_6', 'Feature_7',\n",
       "                                              'Feature_8', 'Feature_9',\n",
       "                                              'Feature_10', 'Feature_11',\n",
       "                                              'Feature_12', 'Feature_13',\n",
       "                                              'Feature_14', 'Feature_15',\n",
       "                                              'Feature_16', 'Feature_17',\n",
       "                                              'Feature_18', 'Featu...\n",
       "                                importance_type=None,\n",
       "                                interaction_constraints=None, learning_rate=None,\n",
       "                                max_bin=None, max_cat_threshold=None,\n",
       "                                max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                max_depth=None, max_leaves=None,\n",
       "                                min_child_weight=None, missing=nan,\n",
       "                                monotone_constraints=None, multi_strategy=None,\n",
       "                                n_estimators=None, n_jobs=-1,\n",
       "                                num_parallel_tree=None,\n",
       "                                objective='multi:softprob', ...))],\n",
       "          verbose=False),\n",
       " '/workspace/Dacon_FSI/automl/pycaret.pkl')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save pipeline\n",
    "exp.save_model(best, '/workspace/Dacon_FSI/automl/pycaret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Imortance : Feature 중요도 확인(autoML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "exp.plot_model(best, plot = 'feature') #KNN등은 안될수도잇음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5bc26\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5bc26_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5bc26_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_5bc26_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_5bc26_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_5bc26_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_5bc26_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_5bc26_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_5bc26_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5bc26_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5bc26_row0_col0\" class=\"data row0 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_5bc26_row0_col1\" class=\"data row0 col1\" >0.0172</td>\n",
       "      <td id=\"T_5bc26_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_5bc26_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_5bc26_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_5bc26_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_5bc26_row0_col6\" class=\"data row0 col6\" >0.0000</td>\n",
       "      <td id=\"T_5bc26_row0_col7\" class=\"data row0 col7\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f28b4bb1870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test set\n",
    "holdout_pred = exp.predict_model(best, data=test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_249</th>\n",
       "      <th>Feature_250</th>\n",
       "      <th>Feature_251</th>\n",
       "      <th>Feature_252</th>\n",
       "      <th>Feature_253</th>\n",
       "      <th>Feature_254</th>\n",
       "      <th>Feature_255</th>\n",
       "      <th>Fraud_Type</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811023</td>\n",
       "      <td>-0.884546</td>\n",
       "      <td>-1.577283</td>\n",
       "      <td>-1.299030</td>\n",
       "      <td>0.632926</td>\n",
       "      <td>0.571585</td>\n",
       "      <td>-0.327909</td>\n",
       "      <td>0.475349</td>\n",
       "      <td>1.155972</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.105103</td>\n",
       "      <td>1.452120</td>\n",
       "      <td>-0.009145</td>\n",
       "      <td>-1.186005</td>\n",
       "      <td>-0.440749</td>\n",
       "      <td>0.715322</td>\n",
       "      <td>0.498263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888021</td>\n",
       "      <td>-1.123688</td>\n",
       "      <td>-1.326016</td>\n",
       "      <td>-1.367326</td>\n",
       "      <td>0.639414</td>\n",
       "      <td>0.498377</td>\n",
       "      <td>-0.550863</td>\n",
       "      <td>0.613569</td>\n",
       "      <td>1.318789</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.869777</td>\n",
       "      <td>1.483557</td>\n",
       "      <td>-0.139447</td>\n",
       "      <td>-1.282944</td>\n",
       "      <td>-0.430462</td>\n",
       "      <td>0.754942</td>\n",
       "      <td>0.691431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.313471</td>\n",
       "      <td>-1.439565</td>\n",
       "      <td>-1.062526</td>\n",
       "      <td>-1.363477</td>\n",
       "      <td>0.571448</td>\n",
       "      <td>0.384888</td>\n",
       "      <td>-0.757616</td>\n",
       "      <td>0.035276</td>\n",
       "      <td>1.262327</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.895217</td>\n",
       "      <td>1.005348</td>\n",
       "      <td>-0.225797</td>\n",
       "      <td>-1.341675</td>\n",
       "      <td>-0.667736</td>\n",
       "      <td>0.815928</td>\n",
       "      <td>0.935092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.873229</td>\n",
       "      <td>-1.124686</td>\n",
       "      <td>-1.302504</td>\n",
       "      <td>-1.374289</td>\n",
       "      <td>0.631282</td>\n",
       "      <td>0.500220</td>\n",
       "      <td>-0.561970</td>\n",
       "      <td>0.605419</td>\n",
       "      <td>1.325131</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.847030</td>\n",
       "      <td>1.481797</td>\n",
       "      <td>-0.154946</td>\n",
       "      <td>-1.295815</td>\n",
       "      <td>-0.430337</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>0.688607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.946826</td>\n",
       "      <td>-1.074133</td>\n",
       "      <td>-1.323102</td>\n",
       "      <td>-1.346335</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.468431</td>\n",
       "      <td>-0.583506</td>\n",
       "      <td>0.655180</td>\n",
       "      <td>1.330531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916018</td>\n",
       "      <td>1.519735</td>\n",
       "      <td>-0.076931</td>\n",
       "      <td>-1.276022</td>\n",
       "      <td>-0.434645</td>\n",
       "      <td>0.749384</td>\n",
       "      <td>0.724769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>119995.0</td>\n",
       "      <td>1.623411</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>-0.943115</td>\n",
       "      <td>-0.919865</td>\n",
       "      <td>0.613972</td>\n",
       "      <td>-0.072547</td>\n",
       "      <td>-0.772227</td>\n",
       "      <td>0.636131</td>\n",
       "      <td>0.719791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>-0.210427</td>\n",
       "      <td>-0.175270</td>\n",
       "      <td>-0.495574</td>\n",
       "      <td>1.773592</td>\n",
       "      <td>0.515972</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>119996.0</td>\n",
       "      <td>0.870096</td>\n",
       "      <td>-1.126793</td>\n",
       "      <td>-1.299274</td>\n",
       "      <td>-1.383808</td>\n",
       "      <td>0.631674</td>\n",
       "      <td>0.500794</td>\n",
       "      <td>-0.557830</td>\n",
       "      <td>0.599159</td>\n",
       "      <td>1.329966</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.840598</td>\n",
       "      <td>1.478379</td>\n",
       "      <td>-0.159223</td>\n",
       "      <td>-1.300883</td>\n",
       "      <td>-0.417705</td>\n",
       "      <td>0.762833</td>\n",
       "      <td>0.687601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>119997.0</td>\n",
       "      <td>0.868297</td>\n",
       "      <td>-1.144031</td>\n",
       "      <td>-1.300323</td>\n",
       "      <td>-1.420733</td>\n",
       "      <td>0.621814</td>\n",
       "      <td>0.511076</td>\n",
       "      <td>-0.530012</td>\n",
       "      <td>0.582274</td>\n",
       "      <td>1.344216</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.803948</td>\n",
       "      <td>1.476241</td>\n",
       "      <td>-0.148063</td>\n",
       "      <td>-1.315493</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.679863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>119998.0</td>\n",
       "      <td>1.741475</td>\n",
       "      <td>-0.555028</td>\n",
       "      <td>-1.381276</td>\n",
       "      <td>-1.354762</td>\n",
       "      <td>0.731899</td>\n",
       "      <td>0.196707</td>\n",
       "      <td>-0.782255</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>1.151647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335599</td>\n",
       "      <td>0.659950</td>\n",
       "      <td>-0.109424</td>\n",
       "      <td>-1.008523</td>\n",
       "      <td>1.437853</td>\n",
       "      <td>0.660298</td>\n",
       "      <td>1.105610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>119999.0</td>\n",
       "      <td>1.344253</td>\n",
       "      <td>0.383368</td>\n",
       "      <td>-0.180044</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.652885</td>\n",
       "      <td>-0.122788</td>\n",
       "      <td>-0.923629</td>\n",
       "      <td>-0.671357</td>\n",
       "      <td>1.285698</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.954180</td>\n",
       "      <td>0.312254</td>\n",
       "      <td>-0.555165</td>\n",
       "      <td>-1.087550</td>\n",
       "      <td>2.306502</td>\n",
       "      <td>0.551553</td>\n",
       "      <td>1.228507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
       "0            0.0   0.811023  -0.884546  -1.577283  -1.299030   0.632926   \n",
       "1            1.0   0.888021  -1.123688  -1.326016  -1.367326   0.639414   \n",
       "2            2.0   1.313471  -1.439565  -1.062526  -1.363477   0.571448   \n",
       "3            3.0   0.873229  -1.124686  -1.302504  -1.374289   0.631282   \n",
       "4            4.0   0.946826  -1.074133  -1.323102  -1.346335   0.638889   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "119995  119995.0   1.623411   0.018297  -0.943115  -0.919865   0.613972   \n",
       "119996  119996.0   0.870096  -1.126793  -1.299274  -1.383808   0.631674   \n",
       "119997  119997.0   0.868297  -1.144031  -1.300323  -1.420733   0.621814   \n",
       "119998  119998.0   1.741475  -0.555028  -1.381276  -1.354762   0.731899   \n",
       "119999  119999.0   1.344253   0.383368  -0.180044  -0.035430   0.652885   \n",
       "\n",
       "        Feature_5  Feature_6  Feature_7  Feature_8  ...  Feature_249  \\\n",
       "0        0.571585  -0.327909   0.475349   1.155972  ...    -2.105103   \n",
       "1        0.498377  -0.550863   0.613569   1.318789  ...    -1.869777   \n",
       "2        0.384888  -0.757616   0.035276   1.262327  ...    -1.895217   \n",
       "3        0.500220  -0.561970   0.605419   1.325131  ...    -1.847030   \n",
       "4        0.468431  -0.583506   0.655180   1.330531  ...    -1.916018   \n",
       "...           ...        ...        ...        ...  ...          ...   \n",
       "119995  -0.072547  -0.772227   0.636131   0.719791  ...     0.479314   \n",
       "119996   0.500794  -0.557830   0.599159   1.329966  ...    -1.840598   \n",
       "119997   0.511076  -0.530012   0.582274   1.344216  ...    -1.803948   \n",
       "119998   0.196707  -0.782255   0.666096   1.151647  ...    -0.335599   \n",
       "119999  -0.122788  -0.923629  -0.671357   1.285698  ...    -1.954180   \n",
       "\n",
       "        Feature_250  Feature_251  Feature_252  Feature_253  Feature_254  \\\n",
       "0          1.452120    -0.009145    -1.186005    -0.440749     0.715322   \n",
       "1          1.483557    -0.139447    -1.282944    -0.430462     0.754942   \n",
       "2          1.005348    -0.225797    -1.341675    -0.667736     0.815928   \n",
       "3          1.481797    -0.154946    -1.295815    -0.430337     0.760087   \n",
       "4          1.519735    -0.076931    -1.276022    -0.434645     0.749384   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "119995    -0.210427    -0.175270    -0.495574     1.773592     0.515972   \n",
       "119996     1.478379    -0.159223    -1.300883    -0.417705     0.762833   \n",
       "119997     1.476241    -0.148063    -1.315493    -0.387314     0.772619   \n",
       "119998     0.659950    -0.109424    -1.008523     1.437853     0.660298   \n",
       "119999     0.312254    -0.555165    -1.087550     2.306502     0.551553   \n",
       "\n",
       "        Feature_255  Fraud_Type  prediction_label  prediction_score  \n",
       "0          0.498263         0.0                12            0.5504  \n",
       "1          0.691431         0.0                 8            0.4713  \n",
       "2          0.935092         0.0                12            0.5540  \n",
       "3          0.688607         0.0                12            0.8703  \n",
       "4          0.724769         0.0                12            0.6809  \n",
       "...             ...         ...               ...               ...  \n",
       "119995     0.992709         0.0                12            0.5025  \n",
       "119996     0.687601         0.0                12            0.6157  \n",
       "119997     0.679863         0.0                12            0.7509  \n",
       "119998     1.105610         0.0                12            0.5444  \n",
       "119999     1.228507         0.0                12            0.5103  \n",
       "\n",
       "[120000 rows x 260 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Fraud_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Fraud_Type\n",
       "0  TEST_000000          12\n",
       "1  TEST_000001           8\n",
       "2  TEST_000002          12\n",
       "3  TEST_000003          12\n",
       "4  TEST_000004          12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류 예측 결과 제출 데이터프레임(DataFrame)\n",
    "# 분류 예측 결과 데이터프레임 파일명을 반드시 clf_submission.csv 로 지정해야합니다.\n",
    "clf_submission = pd.read_csv(\"/workspace/Dataset/FSI/sample_submission.csv\")\n",
    "clf_submission[\"Fraud_Type\"] = holdout_pred.prediction_label\n",
    "clf_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID Fraud_Type\n",
      "0       TEST_000000          m\n",
      "1       TEST_000001          i\n",
      "2       TEST_000002          m\n",
      "3       TEST_000003          m\n",
      "4       TEST_000004          m\n",
      "...             ...        ...\n",
      "119995  TEST_119995          m\n",
      "119996  TEST_119996          m\n",
      "119997  TEST_119997          m\n",
      "119998  TEST_119998          m\n",
      "119999  TEST_119999          m\n",
      "\n",
      "[120000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    0: 'a',\n",
    "    1: 'b',\n",
    "    2: 'c',\n",
    "    3: 'd',\n",
    "    4: 'e',\n",
    "    5: 'f',\n",
    "    6: 'g',\n",
    "    7: 'h',\n",
    "    8: 'i',\n",
    "    9: 'j',\n",
    "    10: 'k',\n",
    "    11: 'l',\n",
    "    12: 'm'\n",
    "}\n",
    "\n",
    "# Apply the mapping to get the original labels\n",
    "clf_submission['Fraud_Type'] = clf_submission['Fraud_Type'].map(mapping)\n",
    "\n",
    "# Print the results\n",
    "print(clf_submission[['ID', 'Fraud_Type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_247</th>\n",
       "      <th>Feature_248</th>\n",
       "      <th>Feature_249</th>\n",
       "      <th>Feature_250</th>\n",
       "      <th>Feature_251</th>\n",
       "      <th>Feature_252</th>\n",
       "      <th>Feature_253</th>\n",
       "      <th>Feature_254</th>\n",
       "      <th>Feature_255</th>\n",
       "      <th>Fraud_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885936</td>\n",
       "      <td>-1.122598</td>\n",
       "      <td>-1.314229</td>\n",
       "      <td>-1.367108</td>\n",
       "      <td>0.636343</td>\n",
       "      <td>0.494710</td>\n",
       "      <td>-0.562223</td>\n",
       "      <td>0.612917</td>\n",
       "      <td>1.319658</td>\n",
       "      <td>1.090834</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.017465</td>\n",
       "      <td>1.376495</td>\n",
       "      <td>-1.870669</td>\n",
       "      <td>1.480747</td>\n",
       "      <td>-0.147397</td>\n",
       "      <td>-1.287513</td>\n",
       "      <td>-0.439808</td>\n",
       "      <td>0.755857</td>\n",
       "      <td>0.698420</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880793</td>\n",
       "      <td>-1.124869</td>\n",
       "      <td>-1.307368</td>\n",
       "      <td>-1.371465</td>\n",
       "      <td>0.636384</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>-0.566216</td>\n",
       "      <td>0.605696</td>\n",
       "      <td>1.323565</td>\n",
       "      <td>1.098862</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021952</td>\n",
       "      <td>1.372676</td>\n",
       "      <td>-1.863031</td>\n",
       "      <td>1.475643</td>\n",
       "      <td>-0.155939</td>\n",
       "      <td>-1.293964</td>\n",
       "      <td>-0.427294</td>\n",
       "      <td>0.758540</td>\n",
       "      <td>0.699163</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.377666</td>\n",
       "      <td>0.339209</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>-1.409007</td>\n",
       "      <td>-1.089655</td>\n",
       "      <td>1.679317</td>\n",
       "      <td>0.855296</td>\n",
       "      <td>0.394174</td>\n",
       "      <td>0.803502</td>\n",
       "      <td>0.974490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277106</td>\n",
       "      <td>-0.373129</td>\n",
       "      <td>0.285689</td>\n",
       "      <td>1.221917</td>\n",
       "      <td>1.118260</td>\n",
       "      <td>-1.194958</td>\n",
       "      <td>1.369991</td>\n",
       "      <td>0.624189</td>\n",
       "      <td>-0.188979</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.879569</td>\n",
       "      <td>-1.125141</td>\n",
       "      <td>-1.307529</td>\n",
       "      <td>-1.372353</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>-0.564435</td>\n",
       "      <td>0.606254</td>\n",
       "      <td>1.323713</td>\n",
       "      <td>1.098156</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.020210</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>-1.860295</td>\n",
       "      <td>1.477029</td>\n",
       "      <td>-0.154930</td>\n",
       "      <td>-1.293683</td>\n",
       "      <td>-0.428403</td>\n",
       "      <td>0.758641</td>\n",
       "      <td>0.696971</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.748027</td>\n",
       "      <td>-1.183629</td>\n",
       "      <td>-1.236481</td>\n",
       "      <td>-1.185666</td>\n",
       "      <td>0.453873</td>\n",
       "      <td>0.863147</td>\n",
       "      <td>-0.491778</td>\n",
       "      <td>0.509654</td>\n",
       "      <td>1.200555</td>\n",
       "      <td>0.866810</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.098041</td>\n",
       "      <td>1.094831</td>\n",
       "      <td>-1.407425</td>\n",
       "      <td>1.595232</td>\n",
       "      <td>-0.024976</td>\n",
       "      <td>-1.390815</td>\n",
       "      <td>0.035027</td>\n",
       "      <td>0.800254</td>\n",
       "      <td>0.443231</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0   0.885936  -1.122598  -1.314229  -1.367108   0.636343   0.494710   \n",
       "1   0.880793  -1.124869  -1.307368  -1.371465   0.636384   0.496053   \n",
       "2  -0.377666   0.339209   0.398247  -1.409007  -1.089655   1.679317   \n",
       "3   0.879569  -1.125141  -1.307529  -1.372353   0.635688   0.496774   \n",
       "4   0.748027  -1.183629  -1.236481  -1.185666   0.453873   0.863147   \n",
       "\n",
       "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_247  Feature_248  \\\n",
       "0  -0.562223   0.612917   1.319658   1.090834  ...    -1.017465     1.376495   \n",
       "1  -0.566216   0.605696   1.323565   1.098862  ...    -1.021952     1.372676   \n",
       "2   0.855296   0.394174   0.803502   0.974490  ...    -0.277106    -0.373129   \n",
       "3  -0.564435   0.606254   1.323713   1.098156  ...    -1.020210     1.371682   \n",
       "4  -0.491778   0.509654   1.200555   0.866810  ...    -1.098041     1.094831   \n",
       "\n",
       "   Feature_249  Feature_250  Feature_251  Feature_252  Feature_253  \\\n",
       "0    -1.870669     1.480747    -0.147397    -1.287513    -0.439808   \n",
       "1    -1.863031     1.475643    -0.155939    -1.293964    -0.427294   \n",
       "2     0.285689     1.221917     1.118260    -1.194958     1.369991   \n",
       "3    -1.860295     1.477029    -0.154930    -1.293683    -0.428403   \n",
       "4    -1.407425     1.595232    -0.024976    -1.390815     0.035027   \n",
       "\n",
       "   Feature_254  Feature_255  Fraud_Type  \n",
       "0     0.755857     0.698420        12.0  \n",
       "1     0.758540     0.699163        12.0  \n",
       "2     0.624189    -0.188979        12.0  \n",
       "3     0.758641     0.696971        12.0  \n",
       "4     0.800254     0.443231        12.0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성 데이터 생성 결과 제출 데이터프레임(DataFrame)\n",
    "# 합성 데이터 생성 결과 데이터프레임 파일명을 반드시 syn_submission.csv 로 지정해야합니다.\n",
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(*) 저장 시 각 파일명을 반드시 확인해주세요.\n",
    "    1. 분류 예측 결과 데이터프레임 파일명 = clf_submission.csv\n",
    "    2. 합성 데이터 생성 결과 데이터프레임 파일명 = syn_submission.csv\n",
    "\n",
    "(*) 제출 파일(zip) 내에 두 개의 데이터프레임이 각각 위의 파일명으로 반드시 존재해야합니다.\n",
    "(*) 파일명을 일치시키지 않으면 채점이 불가능합니다.\n",
    "'''\n",
    "\n",
    "os.makedirs('/workspace/Dacon_FSI/automl/pycaret/submission', exist_ok=True)\n",
    "os.chdir(\"/workspace/Dacon_FSI/automl/pycaret/submission\")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "clf_submission.to_csv('/workspace/Dacon_FSI/automl/pycaret/submission/clf_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "all_synthetic_data.to_csv('/workspace/Dacon_FSI/automl/pycaret/submission/syn_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# ZIP 파일 생성 및 CSV 파일 추가\n",
    "with zipfile.ZipFile(\"/workspace/Dacon_FSI/automl/pycaret/submission/baseline_submission.zip\", 'w') as submission:\n",
    "    submission.write('clf_submission.csv')\n",
    "    submission.write('syn_submission.csv')\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
