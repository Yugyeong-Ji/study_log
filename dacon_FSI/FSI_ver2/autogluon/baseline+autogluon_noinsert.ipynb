{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalous Financial Transaction Detection\n",
    "\n",
    "ë³¸ ëŒ€íšŒì˜ ê³¼ì œëŠ” ê¸ˆìœµ ê±°ë˜ ë°ì´í„°ì—ì„œ **ì´ìƒ ê±°ë˜ë¥¼ íƒì§€í•˜ëŠ” ê¸°ëŠ¥**ì„ ê°œì„ í•˜ê³  í™œìš©ë„ë¥¼ ë†’ì´ëŠ” ë¶„ë¥˜ AIëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "\n",
    "íŠ¹íˆ, í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì˜¤í”ˆì†ŒìŠ¤ ìƒì„±í˜• AI ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¶€ì¡±í•œ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ë³´ì™„í•˜ê³ , ì´ë¥¼ í†µí•´ ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ í•µì‹¬ ëª©í‘œì…ë‹ˆë‹¤. \n",
    "\n",
    "ì´ëŸ¬í•œ ì ‘ê·¼ì„ í†µí•´ ê¸ˆìœµë³´ì•ˆì— íŠ¹í™”ëœ ë°ì´í„° ë¶„ì„ ë° í™œìš© ì—­ëŸ‰ì„ ê°•í™”í•˜ì—¬ ì „ë¬¸ ì¸ë ¥ì„ ì–‘ì„±í•˜ê³ , ê¸ˆìœµê¶Œì˜ AI í™œìš© ì–´ë ¤ì›€ì— ë”°ë¥¸ í•´ê²° ë°©ì•ˆì„ í•¨ê»˜ ëª¨ìƒ‰í•˜ë©° ê¸ˆìœµ ì‚°ì—…ì˜ AI í™œìš© í™œì„±í™”ë¥¼ ì§€ì›í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„± ê´€ë ¨\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ì „ì²˜ë¦¬\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸\n",
    "import xgboost as xgb\n",
    "\n",
    "# í•©ì„± ë°ì´í„° ìƒì„±\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# To ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìƒì„± ğŸ­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.read_csv(\"/workspace/Dataset/FSI/train.csv\")\n",
    "test_all = pd.read_csv(\"/workspace/Dataset/FSI/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_all.drop(columns=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud_Type\n",
       "m    118800\n",
       "a       100\n",
       "j       100\n",
       "h       100\n",
       "k       100\n",
       "c       100\n",
       "g       100\n",
       "i       100\n",
       "b       100\n",
       "f       100\n",
       "d       100\n",
       "e       100\n",
       "l       100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Fraud_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(*) ë¦¬ë”ë³´ë“œ ì‚°ì‹ ì¤‘ ìƒì„±ë°ì´í„°ì˜ ìµëª…ì„±(TCAP)ì±„ì ì„ ìœ„í•´ ê° í´ë˜ìŠ¤ ë³„ë¡œ 1000ê°œì˜ ìƒì„±ë°ì´í„°ê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "(*) ë³¸ ë² ì´ìŠ¤ ë¼ì¸ì—ì„œëŠ” \"Fraud_Type\" 13ì¢…ë¥˜ì— ëŒ€í•´ 1000ê°œì”© , ì´ 13,000ê°œì˜ ë°ì´í„°ë¥¼ ìƒì„±í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "(*) ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ìƒì„± ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì—ëŠ” ìƒì„± ë°ì´í„°ì˜ Row ê°œìˆ˜ì— ì œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨, ë¦¬ë”ë³´ë“œ í‰ê°€ë¥¼ ìœ„í•´ ì œì¶œì„ í•˜ëŠ” ìƒì„± ë°ì´í„° í”„ë ˆì„ì€ ìµëª…ì„±(TCAP) í‰ê°€ë¥¼ ìœ„í•¨ì´ë©°, ìœ„ì˜ ì¡°ê±´ì„ ê°–ì¶˜ ìƒì„± ë°ì´í„°ë¥¼ ì œì¶œí•´ì•¼í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "N_CLS_PER_GEN = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [01:17<00:00,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final All Synthetic Data Shape: (13000, 63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def handle_outliers(series, n_std=3):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    z_scores = np.abs(stats.zscore(series))\n",
    "    return series.mask(z_scores > n_std, mean)\n",
    "\n",
    "# Time_difference ì»¬ëŸ¼ì„ ì´ ì´ˆë¡œ ë³€í™˜ ë° ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "train['Time_difference_seconds'] = pd.to_timedelta(train['Time_difference']).dt.total_seconds()\n",
    "train['Time_difference_seconds'] = handle_outliers(train['Time_difference_seconds'])\n",
    "\n",
    "\n",
    "# ëª¨ë“  Fraud_Type ëª©ë¡ ìƒì„± (m í¬í•¨)\n",
    "fraud_types = train['Fraud_Type'].unique()\n",
    "\n",
    "# ëª¨ë“  í•©ì„± ë°ì´í„°ë¥¼ ì €ì¥í•  DataFrame ì´ˆê¸°í™”\n",
    "all_synthetic_data = pd.DataFrame()\n",
    "\n",
    "N_SAMPLE = 100\n",
    "\n",
    "# ê° Fraud_Typeì— ëŒ€í•´ í•©ì„± ë°ì´í„° ìƒì„± ë° ì €ì¥\n",
    "for fraud_type in tqdm(fraud_types):\n",
    "    \n",
    "    # í•´ë‹¹ Fraud_Typeì— ëŒ€í•œ ì„œë¸Œì…‹ ìƒì„±\n",
    "    subset = train[train[\"Fraud_Type\"] == fraud_type]\n",
    "\n",
    "    # ëª¨ë“  Fraud_Typeì— ëŒ€í•´ 100ê°œì”© ìƒ˜í”Œë§\n",
    "    subset = subset.sample(n=N_SAMPLE, random_state=42)\n",
    "    \n",
    "    # Time_difference ì—´ ì œì™¸ (ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜ëœ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)\n",
    "    subset = subset.drop('Time_difference', axis=1)\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ìƒì„± ë° ëª¨ë¸ í•™ìŠµ\n",
    "    metadata = SingleTableMetadata()\n",
    "\n",
    "    metadata.detect_from_dataframe(subset)\n",
    "    metadata.set_primary_key(None)\n",
    "\n",
    "    # ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    column_sdtypes = {\n",
    "        'Account_initial_balance': 'numerical',\n",
    "        'Account_balance': 'numerical',\n",
    "        'Customer_identification_number': 'categorical',  \n",
    "        'Customer_personal_identifier': 'categorical',\n",
    "        'Account_account_number': 'categorical',\n",
    "        'IP_Address': 'ipv4_address',  \n",
    "        'Location': 'categorical',\n",
    "        'Recipient_Account_Number': 'categorical',\n",
    "        'Fraud_Type': 'categorical',\n",
    "        'Time_difference_seconds': 'numerical',\n",
    "        'Customer_Birthyear': 'numerical'\n",
    "    }\n",
    "\n",
    "    # ê° ì»¬ëŸ¼ì— ëŒ€í•´ ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    for column, sdtype in column_sdtypes.items():\n",
    "        metadata.update_column(\n",
    "            column_name=column,\n",
    "            sdtype=sdtype\n",
    "        )\n",
    "        \n",
    "    synthesizer = CTGANSynthesizer(\n",
    "                            metadata,\n",
    "                            epochs=100\n",
    "                        )\n",
    "    synthesizer.fit(subset)\n",
    "\n",
    "    synthetic_subset = synthesizer.sample(num_rows=N_CLS_PER_GEN)\n",
    "    \n",
    "    # ìƒì„±ëœ Time_difference_secondsì˜ ì´ìƒì¹˜ ì²˜ë¦¬\n",
    "    synthetic_subset['Time_difference_seconds'] = handle_outliers(synthetic_subset['Time_difference_seconds'])\n",
    "    \n",
    "    # Time_difference_secondsë¥¼ ë‹¤ì‹œ timedeltaë¡œ ë³€í™˜\n",
    "    synthetic_subset['Time_difference'] = pd.to_timedelta(synthetic_subset['Time_difference_seconds'], unit='s')\n",
    "    \n",
    "    # Time_difference_seconds ì»¬ëŸ¼ ì œê±°\n",
    "    synthetic_subset = synthetic_subset.drop('Time_difference_seconds', axis=1)\n",
    "    \n",
    "    # ìƒì„±ëœ ë°ì´í„°ë¥¼ all_synthetic_dataì— ì¶”ê°€\n",
    "    all_synthetic_data = pd.concat([all_synthetic_data, synthetic_subset], ignore_index=True)\n",
    "# ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "print(\"\\nFinal All Synthetic Data Shape:\", all_synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Birthyear</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_personal_identifier</th>\n",
       "      <th>Customer_identification_number</th>\n",
       "      <th>Customer_registration_datetime</th>\n",
       "      <th>Customer_credit_rating</th>\n",
       "      <th>Customer_flag_change_of_authentication_1</th>\n",
       "      <th>Customer_flag_change_of_authentication_2</th>\n",
       "      <th>Customer_flag_change_of_authentication_3</th>\n",
       "      <th>Customer_flag_change_of_authentication_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_bank_branch_transaction_datetime</th>\n",
       "      <th>Flag_deposit_more_than_tenMillion</th>\n",
       "      <th>Unused_account_status</th>\n",
       "      <th>Recipient_account_suspend_status</th>\n",
       "      <th>Number_of_transaction_with_the_account</th>\n",
       "      <th>Transaction_history_with_the_account</th>\n",
       "      <th>First_time_iOS_by_vulnerable_user</th>\n",
       "      <th>Fraud_Type</th>\n",
       "      <th>Transaction_resumed_date</th>\n",
       "      <th>Time_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>female</td>\n",
       "      <td>ê¹€ê´‘ìˆ˜</td>\n",
       "      <td>UXhaKw-xjkJBGo</td>\n",
       "      <td>2005-06-15 17:30:50</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2011-07-31 06:32:32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>male</td>\n",
       "      <td>ì—„ì˜ì‹</td>\n",
       "      <td>tLlZuQ-fweLsGp</td>\n",
       "      <td>2005-08-17 23:20:53</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>female</td>\n",
       "      <td>ê¹€ì¤‘ìˆ˜</td>\n",
       "      <td>aOYDbp-pOgthCC</td>\n",
       "      <td>2004-07-07 10:19:51</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2006-12-17 12:07:09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>female</td>\n",
       "      <td>ì¥ë™í˜„</td>\n",
       "      <td>STcZwr-Uuvgbip</td>\n",
       "      <td>2003-03-12 21:28:24</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2013-03-05 04:08:58</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>male</td>\n",
       "      <td>í•œì¤€í˜</td>\n",
       "      <td>WrnKdP-lsuiVtb</td>\n",
       "      <td>2007-09-20 08:44:38</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-07-27 17:39:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Birthyear Customer_Gender Customer_personal_identifier  \\\n",
       "0                1988          female                          ê¹€ê´‘ìˆ˜   \n",
       "1                1976            male                          ì—„ì˜ì‹   \n",
       "2                2004          female                          ê¹€ì¤‘ìˆ˜   \n",
       "3                1980          female                          ì¥ë™í˜„   \n",
       "4                1981            male                          í•œì¤€í˜   \n",
       "\n",
       "  Customer_identification_number Customer_registration_datetime  \\\n",
       "0                 UXhaKw-xjkJBGo            2005-06-15 17:30:50   \n",
       "1                 tLlZuQ-fweLsGp            2005-08-17 23:20:53   \n",
       "2                 aOYDbp-pOgthCC            2004-07-07 10:19:51   \n",
       "3                 STcZwr-Uuvgbip            2003-03-12 21:28:24   \n",
       "4                 WrnKdP-lsuiVtb            2007-09-20 08:44:38   \n",
       "\n",
       "  Customer_credit_rating  Customer_flag_change_of_authentication_1  \\\n",
       "0                      A                                         1   \n",
       "1                      C                                         1   \n",
       "2                      B                                         1   \n",
       "3                      B                                         1   \n",
       "4                      E                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_2  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   Customer_flag_change_of_authentication_3  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_4  ...  \\\n",
       "0                                         1  ...   \n",
       "1                                         1  ...   \n",
       "2                                         1  ...   \n",
       "3                                         1  ...   \n",
       "4                                         1  ...   \n",
       "\n",
       "   Last_bank_branch_transaction_datetime  Flag_deposit_more_than_tenMillion  \\\n",
       "0                    2011-07-31 06:32:32                                  0   \n",
       "1                    2004-07-10 20:11:30                                  0   \n",
       "2                    2006-12-17 12:07:09                                  0   \n",
       "3                    2004-07-10 20:11:30                                  1   \n",
       "4                    2004-07-27 17:39:06                                  0   \n",
       "\n",
       "   Unused_account_status Recipient_account_suspend_status  \\\n",
       "0                      1                                1   \n",
       "1                      1                                0   \n",
       "2                      1                                0   \n",
       "3                      1                                0   \n",
       "4                      0                                0   \n",
       "\n",
       "   Number_of_transaction_with_the_account  \\\n",
       "0                                       1   \n",
       "1                                       1   \n",
       "2                                       0   \n",
       "3                                       2   \n",
       "4                                       0   \n",
       "\n",
       "   Transaction_history_with_the_account  First_time_iOS_by_vulnerable_user  \\\n",
       "0                                     0                                  0   \n",
       "1                                     2                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "\n",
       "   Fraud_Type  Transaction_resumed_date  Time_difference  \n",
       "0           m       2004-07-10 20:11:30  0 days 00:01:38  \n",
       "1           m       2004-07-10 20:11:30  0 days 00:01:38  \n",
       "2           m       2004-07-10 20:11:30  0 days 00:01:38  \n",
       "3           m       2013-03-05 04:08:58  0 days 00:01:38  \n",
       "4           m       2004-07-10 20:11:30  0 days 00:01:38  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì›ë³¸ ë°ì´í„°ì™€ concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133000, 63)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_train = train_all.drop(columns=\"ID\")\n",
    "train_total = pd.concat([origin_train, all_synthetic_data])\n",
    "train_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 1 : Select x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_total.drop(columns=['Fraud_Type'])\n",
    "train_y = train_total['Fraud_Type']\n",
    "\n",
    "test_x = test_all.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 2 : ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë˜ ë ˆì´ë¸”: a, ë³€í™˜ëœ ìˆ«ì: 0\n",
      "ì›ë˜ ë ˆì´ë¸”: b, ë³€í™˜ëœ ìˆ«ì: 1\n",
      "ì›ë˜ ë ˆì´ë¸”: c, ë³€í™˜ëœ ìˆ«ì: 2\n",
      "ì›ë˜ ë ˆì´ë¸”: d, ë³€í™˜ëœ ìˆ«ì: 3\n",
      "ì›ë˜ ë ˆì´ë¸”: e, ë³€í™˜ëœ ìˆ«ì: 4\n",
      "ì›ë˜ ë ˆì´ë¸”: f, ë³€í™˜ëœ ìˆ«ì: 5\n",
      "ì›ë˜ ë ˆì´ë¸”: g, ë³€í™˜ëœ ìˆ«ì: 6\n",
      "ì›ë˜ ë ˆì´ë¸”: h, ë³€í™˜ëœ ìˆ«ì: 7\n",
      "ì›ë˜ ë ˆì´ë¸”: i, ë³€í™˜ëœ ìˆ«ì: 8\n",
      "ì›ë˜ ë ˆì´ë¸”: j, ë³€í™˜ëœ ìˆ«ì: 9\n",
      "ì›ë˜ ë ˆì´ë¸”: k, ë³€í™˜ëœ ìˆ«ì: 10\n",
      "ì›ë˜ ë ˆì´ë¸”: l, ë³€í™˜ëœ ìˆ«ì: 11\n",
      "ì›ë˜ ë ˆì´ë¸”: m, ë³€í™˜ëœ ìˆ«ì: 12\n"
     ]
    }
   ],
   "source": [
    "le_subclass = LabelEncoder()\n",
    "train_y_encoded = le_subclass.fit_transform(train_y)\n",
    "\n",
    "# ë³€í™˜ëœ ë ˆì´ë¸” í™•ì¸\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"ì›ë˜ ë ˆì´ë¸”: {label}, ë³€í™˜ëœ ìˆ«ì: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x\n",
    "# 'Time_difference' ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "train_x['Time_difference'] = train_x['Time_difference'].astype(str)\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "categorical_columns = train_x.select_dtypes(include=['object', 'category']).columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„° ì¸ì½”ë”©\n",
    "train_x_encoded = train_x.copy()\n",
    "train_x_encoded[categorical_columns] = ordinal_encoder.fit_transform(train_x[categorical_columns])\n",
    "\n",
    "# íŠ¹ì„± ìˆœì„œ ì €ì¥\n",
    "feature_order = train_x_encoded.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240824_144150\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          28\n",
      "Memory Avail:       19.71 GB / 31.23 GB (63.1%)\n",
      "Disk Space Avail:   891.27 GB / 1006.85 GB (88.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (106400 samples, 54.48 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240824_144150\"\n",
      "Train Data Rows:    106400\n",
      "Train Data Columns: 62\n",
      "Label Column:       Fraud_Type\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 13) unique label values:  [12, 11, 9, 1, 0, 6, 7, 10, 2, 3]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 13\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20184.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 50.33 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 27 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Another_Person_Account']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 24 | ['Customer_Gender', 'Customer_personal_identifier', 'Customer_identification_number', 'Customer_registration_datetime', 'Customer_credit_rating', ...]\n",
      "\t\t('int', [])   : 37 | ['Customer_Birthyear', 'Customer_flag_change_of_authentication_1', 'Customer_flag_change_of_authentication_2', 'Customer_flag_change_of_authentication_3', 'Customer_flag_change_of_authentication_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 21 | ['Customer_personal_identifier', 'Customer_identification_number', 'Customer_registration_datetime', 'Customer_credit_rating', 'Customer_loan_type', ...]\n",
      "\t\t('int', [])       : 13 | ['Customer_Birthyear', 'Account_initial_balance', 'Account_balance', 'Account_amount_daily_limit', 'Account_remaining_amount_daily_limit_exceeded', ...]\n",
      "\t\t('int', ['bool']) : 27 | ['Customer_Gender', 'Customer_flag_change_of_authentication_1', 'Customer_flag_change_of_authentication_2', 'Customer_flag_change_of_authentication_3', 'Customer_flag_change_of_authentication_4', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t61 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 30.34 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.023496240601503758, Train Rows: 103900, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.962\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.962\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9888\t = Validation score   (accuracy)\n",
      "\t48.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9892\t = Validation score   (accuracy)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9944\t = Validation score   (accuracy)\n",
      "\t5.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t9.75s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t8.12s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9892\t = Validation score   (accuracy)\n",
      "\t29.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9776\t = Validation score   (accuracy)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9732\t = Validation score   (accuracy)\n",
      "\t2.28s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9924\t = Validation score   (accuracy)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9872\t = Validation score   (accuracy)\n",
      "\t25.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9908\t = Validation score   (accuracy)\n",
      "\t14.68s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 0.5, 'XGBoost': 0.5}\n",
      "\t0.9948\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 161.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 97363.5 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240824_144150\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "train_data = train_x_encoded.copy()\n",
    "train_data['Fraud_Type'] = train_y_encoded\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_split, val_data_split = train_test_split(train_data, test_size=0.2, random_state=42, stratify=train_data['Fraud_Type'])\n",
    "\n",
    "# Train the model\n",
    "predictor = TabularPredictor(label='Fraud_Type', eval_metric='accuracy').fit(train_data_split)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Type: 12\n",
      " - Accuracy: 0.9997078464106844\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 8\n",
      " - Accuracy: 0.9318181818181818\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 3\n",
      " - Accuracy: 0.9181818181818182\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 5\n",
      " - Accuracy: 0.9681818181818181\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 10\n",
      " - Accuracy: 0.9681818181818181\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 2\n",
      " - Accuracy: 0.9272727272727272\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 0\n",
      " - Accuracy: 0.9863636363636363\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 9\n",
      " - Accuracy: 0.9363636363636364\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 7\n",
      " - Accuracy: 0.9318181818181818\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 11\n",
      " - Accuracy: 0.9409090909090909\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 4\n",
      " - Accuracy: 0.9181818181818182\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 1\n",
      " - Accuracy: 0.9409090909090909\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n",
      "Fraud Type: 6\n",
      " - Accuracy: 0.9363636363636364\n",
      " - Log Loss: Cannot calculate log loss with only one class present.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "val_predictions = predictor.predict(val_data_split)\n",
    "val_probabilities = predictor.predict_proba(val_data_split)\n",
    "\n",
    "# Get true labels\n",
    "val_true_labels = val_data_split['Fraud_Type']\n",
    "\n",
    "# Calculate and print loss (accuracy and log loss) by fraud type\n",
    "fraud_types = val_true_labels.unique()\n",
    "for fraud_type in fraud_types:\n",
    "    # Get the indices for the current fraud type\n",
    "    indices = val_true_labels == fraud_type\n",
    "\n",
    "    # True labels and predictions for the current fraud type\n",
    "    true_labels = val_true_labels[indices]\n",
    "    predictions = val_predictions[indices]\n",
    "    probabilities = val_probabilities.loc[indices]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    # Handle single-class case for log loss\n",
    "    if len(true_labels.unique()) == 1:\n",
    "        print(f\"Fraud Type: {fraud_type}\")\n",
    "        print(f\" - Accuracy: {accuracy}\")\n",
    "        print(f\" - Log Loss: Cannot calculate log loss with only one class present.\\n\")\n",
    "    else:\n",
    "        logloss = log_loss(true_labels, probabilities)\n",
    "        print(f\"Fraud Type: {fraud_type}\")\n",
    "        print(f\" - Accuracy: {accuracy}\")\n",
    "        print(f\" - Log Loss: {logloss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¸ì½”ë”©\n",
    "test_x_encoded = test_x.copy()\n",
    "test_x_encoded[categorical_columns] = ordinal_encoder.transform(test_x[categorical_columns])\n",
    "\n",
    "\n",
    "# íŠ¹ì„± ìˆœì„œ ë§ì¶”ê¸° ë° ë°ì´í„° íƒ€ì… ì¼ì¹˜\n",
    "test_x_encoded = test_x_encoded[feature_order]\n",
    "for col in feature_order:\n",
    "    test_x_encoded[col] = test_x_encoded[col].astype(train_x_encoded[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "predictions = predictor.predict(test_x_encoded)\n",
    "\n",
    "# Reverse transform to get original labels if necessary\n",
    "predictions_label = le_subclass.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Fraud_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID Fraud_Type\n",
       "0  TEST_000000          m\n",
       "1  TEST_000001          m\n",
       "2  TEST_000002          m\n",
       "3  TEST_000003          m\n",
       "4  TEST_000004          c"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ì œì¶œ ë°ì´í„°í”„ë ˆì„(DataFrame)\n",
    "# ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ clf_submission.csv ë¡œ ì§€ì •í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "clf_submission = pd.read_csv(\"/workspace/Dataset/FSI/sample_submission.csv\")\n",
    "clf_submission[\"Fraud_Type\"] = predictions_label\n",
    "clf_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Birthyear</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_personal_identifier</th>\n",
       "      <th>Customer_identification_number</th>\n",
       "      <th>Customer_registration_datetime</th>\n",
       "      <th>Customer_credit_rating</th>\n",
       "      <th>Customer_flag_change_of_authentication_1</th>\n",
       "      <th>Customer_flag_change_of_authentication_2</th>\n",
       "      <th>Customer_flag_change_of_authentication_3</th>\n",
       "      <th>Customer_flag_change_of_authentication_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Last_bank_branch_transaction_datetime</th>\n",
       "      <th>Flag_deposit_more_than_tenMillion</th>\n",
       "      <th>Unused_account_status</th>\n",
       "      <th>Recipient_account_suspend_status</th>\n",
       "      <th>Number_of_transaction_with_the_account</th>\n",
       "      <th>Transaction_history_with_the_account</th>\n",
       "      <th>First_time_iOS_by_vulnerable_user</th>\n",
       "      <th>Fraud_Type</th>\n",
       "      <th>Transaction_resumed_date</th>\n",
       "      <th>Time_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>male</td>\n",
       "      <td>í™í˜„ì£¼</td>\n",
       "      <td>KfGNJu-TCOPGMK</td>\n",
       "      <td>2012-12-10 22:02:43</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-01-30 00:15:58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2011-11-29 20:15:09</td>\n",
       "      <td>2 days 22:32:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1969</td>\n",
       "      <td>male</td>\n",
       "      <td>ìœ¤ì˜í™˜</td>\n",
       "      <td>IoyIKq-ZWDBMWF</td>\n",
       "      <td>2007-12-08 03:23:09</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2008-05-01 03:48:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2014-05-07 10:49:56</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>female</td>\n",
       "      <td>ë°•ì„±ë¯¼</td>\n",
       "      <td>PHfnba-CoTCGQS</td>\n",
       "      <td>2012-12-10 22:02:43</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2009-11-10 02:36:49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2012-03-29 06:30:05</td>\n",
       "      <td>21 days 14:58:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>female</td>\n",
       "      <td>ê¹€ìƒí˜„</td>\n",
       "      <td>SxnCZF-TcUfNki</td>\n",
       "      <td>2008-04-06 05:05:10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2010-06-06 12:34:02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2027-03-11 17:25:08</td>\n",
       "      <td>0 days 00:01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950</td>\n",
       "      <td>female</td>\n",
       "      <td>ê¹€ë¯¼ì„œ</td>\n",
       "      <td>iOOpeU-LJWWQoW</td>\n",
       "      <td>2012-12-10 22:02:43</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-07-10 20:11:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2026-11-02 19:51:34</td>\n",
       "      <td>8 days 07:09:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Birthyear Customer_Gender Customer_personal_identifier  \\\n",
       "0                1950            male                          í™í˜„ì£¼   \n",
       "1                1969            male                          ìœ¤ì˜í™˜   \n",
       "2                1955          female                          ë°•ì„±ë¯¼   \n",
       "3                1950          female                          ê¹€ìƒí˜„   \n",
       "4                1950          female                          ê¹€ë¯¼ì„œ   \n",
       "\n",
       "  Customer_identification_number Customer_registration_datetime  \\\n",
       "0                 KfGNJu-TCOPGMK            2012-12-10 22:02:43   \n",
       "1                 IoyIKq-ZWDBMWF            2007-12-08 03:23:09   \n",
       "2                 PHfnba-CoTCGQS            2012-12-10 22:02:43   \n",
       "3                 SxnCZF-TcUfNki            2008-04-06 05:05:10   \n",
       "4                 iOOpeU-LJWWQoW            2012-12-10 22:02:43   \n",
       "\n",
       "  Customer_credit_rating  Customer_flag_change_of_authentication_1  \\\n",
       "0                      B                                         1   \n",
       "1                      C                                         1   \n",
       "2                      C                                         0   \n",
       "3                      B                                         1   \n",
       "4                      A                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_2  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         1   \n",
       "\n",
       "   Customer_flag_change_of_authentication_3  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   Customer_flag_change_of_authentication_4  ...  \\\n",
       "0                                         1  ...   \n",
       "1                                         0  ...   \n",
       "2                                         1  ...   \n",
       "3                                         1  ...   \n",
       "4                                         1  ...   \n",
       "\n",
       "   Last_bank_branch_transaction_datetime  Flag_deposit_more_than_tenMillion  \\\n",
       "0                    2007-01-30 00:15:58                                  1   \n",
       "1                    2008-05-01 03:48:19                                  0   \n",
       "2                    2009-11-10 02:36:49                                  0   \n",
       "3                    2010-06-06 12:34:02                                  0   \n",
       "4                    2004-07-10 20:11:30                                  0   \n",
       "\n",
       "   Unused_account_status Recipient_account_suspend_status  \\\n",
       "0                      0                                1   \n",
       "1                      0                                1   \n",
       "2                      1                                1   \n",
       "3                      1                                0   \n",
       "4                      0                                1   \n",
       "\n",
       "   Number_of_transaction_with_the_account  \\\n",
       "0                                       0   \n",
       "1                                       1   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "\n",
       "   Transaction_history_with_the_account  First_time_iOS_by_vulnerable_user  \\\n",
       "0                                     3                                  0   \n",
       "1                                     2                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     2                                  0   \n",
       "4                                     0                                  0   \n",
       "\n",
       "   Fraud_Type  Transaction_resumed_date  Time_difference  \n",
       "0           m       2011-11-29 20:15:09  2 days 22:32:44  \n",
       "1           m       2014-05-07 10:49:56  0 days 00:01:38  \n",
       "2           m       2012-03-29 06:30:05 21 days 14:58:49  \n",
       "3           m       2027-03-11 17:25:08  0 days 00:01:38  \n",
       "4           m       2026-11-02 19:51:34  8 days 07:09:19  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ì œì¶œ ë°ì´í„°í”„ë ˆì„(DataFrame)\n",
    "# í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ syn_submission.csv ë¡œ ì§€ì •í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "all_synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(*) ì €ì¥ ì‹œ ê° íŒŒì¼ëª…ì„ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
    "    1. ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª… = clf_submission.csv\n",
    "    2. í•©ì„± ë°ì´í„° ìƒì„± ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ íŒŒì¼ëª… = syn_submission.csv\n",
    "\n",
    "(*) ì œì¶œ íŒŒì¼(zip) ë‚´ì— ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ì´ ê°ê° ìœ„ì˜ íŒŒì¼ëª…ìœ¼ë¡œ ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "(*) íŒŒì¼ëª…ì„ ì¼ì¹˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ ì±„ì ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "# í´ë” ìƒì„± ë° ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½\n",
    "os.makedirs('/workspace/Dataset/FSI/baseline+autogluon/submission', exist_ok=True)\n",
    "os.chdir(\"/workspace/Dataset/FSI/baseline+autogluon/submission/\")\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "clf_submission.to_csv('/workspace/Dataset/FSI/baseline+autogluon/submission/clf_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "all_synthetic_data.to_csv('/workspace/Dataset/FSI/baseline+autogluon/submission/syn_submission.csv', encoding='UTF-8-sig', index=False)\n",
    "\n",
    "# ZIP íŒŒì¼ ìƒì„± ë° CSV íŒŒì¼ ì¶”ê°€\n",
    "with zipfile.ZipFile(\"/workspace/Dataset/FSI/baseline+autogluon/submission/baseline_submission.zip\", 'w') as submission:\n",
    "    submission.write('clf_submission.csv')\n",
    "    submission.write('syn_submission.csv')\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
